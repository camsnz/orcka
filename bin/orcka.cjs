#!/usr/bin/env node

/**
 * This file is generated automatically by the TypeScript compiler.
 * Do not edit this file directly - modify the source files in the src/ directory instead.
 * 
 * orcka - A CLI tool to calculate deterministic SHA sums from various inputs
 * Generated on: 2025-10-02T13:28:58.073Z
 * Ref: https://github.com/camsnz/orcka/blob/18ddc5612b4a8ea8e1c768cb6504786c107591b3/orcka/README.md
 * 
 * Source: https://github.com/camsnz/orcka/tree/HEAD/orcka/
 * Version: 18ddc5612b4a8ea8e1c768cb6504786c107591b3
 */

"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
Object.defineProperty(exports, Symbol.toStringTag, { value: "Module" });
const node_fs = require("node:fs");
const node_path = require("node:path");
const node_child_process = require("node:child_process");
const node_os = require("node:os");
const yaml = require("yaml");
const hcl2json = require("@cdktf/hcl2json");
const node_crypto = require("node:crypto");
function parseArguments(argv, config) {
  const result = {};
  const argMap = /* @__PURE__ */ new Map();
  for (const [key, def] of Object.entries(config.args)) {
    for (const name of def.names) {
      argMap.set(name, key);
    }
  }
  let i = 0;
  while (i < argv.length) {
    const arg = argv[i];
    if (arg === "--help" || arg === "-h") {
      showCommandHelp(config);
      process.exit(0);
    }
    if (!arg.startsWith("--") && !arg.startsWith("-")) {
      throw new Error(`Unexpected argument: ${arg}`);
    }
    const key = argMap.get(arg);
    if (!key) {
      throw new Error(`Unknown argument: ${arg}`);
    }
    const def = config.args[key];
    if (!def.hasValue) {
      result[key] = true;
      i++;
    } else if (def.multiValue) {
      const values = [];
      i++;
      while (i < argv.length && !argv[i].startsWith("-")) {
        values.push(argv[i]);
        i++;
      }
      if (values.length === 0 && def.required) {
        throw new Error(`${arg} requires at least one value`);
      }
      result[key] = values.length === 1 ? values[0] : values;
    } else {
      i++;
      if (i >= argv.length || argv[i].startsWith("-")) {
        if (def.defaultValue !== void 0) {
          result[key] = def.defaultValue;
        } else {
          throw new Error(`${arg} requires a value`);
        }
      } else {
        result[key] = argv[i];
        i++;
      }
    }
  }
  for (const [key, def] of Object.entries(config.args)) {
    if (result[key] === void 0 && def.required) {
      throw new Error(`Required argument missing: ${def.names[0]}`);
    }
    if (result[key] !== void 0 && def.validator) {
      const error = def.validator(result[key]);
      if (error) {
        throw new Error(`${def.names[0]}: ${error}`);
      }
    }
  }
  return result;
}
function showCommandHelp(config) {
  console.log(`
Usage: orcka ${config.name} [options]
`);
  console.log("Options:");
  for (const [_, def] of Object.entries(config.args)) {
    const names = def.names.join(", ");
    const required = def.required ? " (required)" : "";
    const defaultVal = def.defaultValue !== void 0 ? ` (default: ${def.defaultValue})` : "";
    console.log(`  ${names.padEnd(30)} ${def.description}${required}${defaultVal}`);
  }
  if (config.examples && config.examples.length > 0) {
    console.log("\nExamples:");
    for (const example of config.examples) {
      console.log(`  ${example}`);
    }
  }
  console.log();
}
const CommonArgs = {
  file: {
    names: ["--file", "-f"],
    description: "Path to input file",
    hasValue: true
  },
  help: {
    names: ["--help", "-h"],
    description: "Show help message",
    hasValue: false
  }
};
const CONFIG_FILE_NAMES = [
  "orcka.yaml",
  "orcka.yml",
  "orcka.hcl",
  "docker-orcka.yaml",
  "docker-orcka.yml",
  "docker-orcka.hcl"
];
class ConfigDiscovery {
  logger;
  constructor(logger) {
    this.logger = logger;
  }
  /**
   * Find the first available configuration file in the given directory
   */
  findConfigFile(searchDir = ".") {
    const searchedPaths = [];
    this.logger?.verbose(`🔍 Searching for orcka configuration files in: ${searchDir}`);
    for (const fileName of CONFIG_FILE_NAMES) {
      const filePath = node_path.join(searchDir, fileName);
      searchedPaths.push(filePath);
      this.logger?.verbose(`  Checking: ${fileName}`);
      if (node_fs.existsSync(filePath)) {
        this.logger?.verbose(`  ✅ Found: ${fileName}`);
        return {
          found: true,
          filePath,
          fileName,
          searchedPaths
        };
      } else {
        this.logger?.verbose(`  ❌ Not found: ${fileName}`);
      }
    }
    this.logger?.verbose(`❌ No orcka configuration files found in ${searchDir}`);
    return {
      found: false,
      searchedPaths
    };
  }
  /**
   * Get a user-friendly error message when no config file is found
   */
  getNotFoundMessage(searchDir = ".") {
    const fileList = CONFIG_FILE_NAMES.map((name) => `  - ${name}`).join("\n");
    return `No orcka configuration file found in ${searchDir}.

Searched for:
${fileList}

Please create one of these files or specify --file <path> to use a custom location.

Example minimal configuration:
---
project:
  name: my-project
  context: .
  bake:
    - docker-bake.hcl

targets:
  my-service:
    calculate_on:
      always: true
---`;
  }
  /**
   * Validate that the discovered file is readable and appears to be valid
   */
  validateConfigFile(filePath) {
    try {
      if (!node_fs.existsSync(filePath)) {
        return { valid: false, error: `File does not exist: ${filePath}` };
      }
      const supportedExtensions = [".yaml", ".yml", ".hcl"];
      const hasValidExtension = supportedExtensions.some((ext) => filePath.endsWith(ext));
      if (!hasValidExtension) {
        return {
          valid: false,
          error: `Unsupported file extension. Expected: ${supportedExtensions.join(", ")}`
        };
      }
      return { valid: true };
    } catch (error) {
      return {
        valid: false,
        error: `Error validating config file: ${error instanceof Error ? error.message : String(error)}`
      };
    }
  }
}
function statusLine(type, message) {
  const icons = {
    success: "✅",
    error: "❌",
    warning: "⚠️",
    info: "ℹ️"
  };
  return `${icons[type]} ${message}`;
}
function bullet(text, indent2 = 2) {
  return `${" ".repeat(indent2)}• ${text}`;
}
function numbered(text, number, indent2 = 2) {
  return `${" ".repeat(indent2)}${number}. ${text}`;
}
function dash(text, indent2 = 4) {
  return `${" ".repeat(indent2)}- ${text}`;
}
function keyValue(key, value, options = {}) {
  const { keyWidth = 20, separator = ":", indent: indentSize = 0 } = options;
  const paddedKey = key.padEnd(keyWidth);
  const indentStr = " ".repeat(indentSize);
  return `${indentStr}${paddedKey}${separator} ${value}`;
}
function section(title, char = "=") {
  return `
${title}
${char.repeat(title.length)}`;
}
function child(text, indent2 = 5, prefix = "→") {
  return `${" ".repeat(indent2)}${prefix} ${text}`;
}
function getTerminalWidth() {
  return process.stdout.columns || 80;
}
function applyPadding(padding, defaultValue = 0) {
  return {
    top: padding?.top ?? defaultValue,
    bottom: padding?.bottom ?? defaultValue,
    left: padding?.left ?? defaultValue,
    right: padding?.right ?? defaultValue
  };
}
function padText(text, width, align = "left") {
  if (text.length >= width) {
    return text;
  }
  const padding = width - text.length;
  switch (align) {
    case "left":
      return text + " ".repeat(padding);
    case "right":
      return " ".repeat(padding) + text;
    case "center": {
      const leftPad = Math.floor(padding / 2);
      const rightPad = padding - leftPad;
      return " ".repeat(leftPad) + text + " ".repeat(rightPad);
    }
  }
}
function wrapText(text, width) {
  if (width <= 0) return [text];
  if (text.length === 0) return [""];
  const lines = [];
  const words = text.split(/\s+/);
  let currentLine = "";
  for (const word of words) {
    if (word.length > width) {
      if (currentLine) {
        lines.push(currentLine.trim());
        currentLine = "";
      }
      for (let i = 0; i < word.length; i += width) {
        lines.push(word.slice(i, i + width));
      }
      continue;
    }
    const testLine = currentLine ? `${currentLine} ${word}` : word;
    if (testLine.length <= width) {
      currentLine = testLine;
    } else {
      if (currentLine) {
        lines.push(currentLine);
      }
      currentLine = word;
    }
  }
  if (currentLine) {
    lines.push(currentLine);
  }
  return lines.length > 0 ? lines : [""];
}
function applyIndent(lines, indent2 = 0, hangingIndent = 0) {
  if (indent2 === 0 && hangingIndent === 0) {
    return lines;
  }
  return lines.map((line2, index) => {
    const indentSize = index === 0 ? indent2 : indent2 + hangingIndent;
    return " ".repeat(indentSize) + line2;
  });
}
function applyMargin(lines, margin) {
  const result = [];
  for (let i = 0; i < margin.top; i++) {
    result.push("");
  }
  const leftMargin = " ".repeat(margin.left);
  const processedLines = lines.map((line2) => leftMargin + line2);
  result.push(...processedLines);
  for (let i = 0; i < margin.bottom; i++) {
    result.push("");
  }
  return result;
}
function truncateWithEllipsis(text, maxLength, ellipsis = "...") {
  if (text.length <= maxLength) return text;
  if (maxLength <= ellipsis.length) return ellipsis.substring(0, maxLength);
  return text.substring(0, maxLength - ellipsis.length) + ellipsis;
}
function line(char = "-", width = getTerminalWidth()) {
  return char.repeat(Math.max(0, width));
}
function formatText(text, options = {}) {
  const { width = getTerminalWidth(), align = "left", indent: indent2 = 0, hangingIndent = 0, margin } = options;
  const effectiveWidth = width - indent2 - hangingIndent;
  let lines = wrapText(text, effectiveWidth);
  if (text.length > 0) {
    lines = lines.map((line2) => padText(line2, effectiveWidth, align));
  }
  lines = applyIndent(lines, indent2, hangingIndent);
  if (margin) {
    const paddingValues = applyPadding(margin);
    lines = applyMargin(lines, paddingValues);
  }
  return lines;
}
function banner(text, options = {}) {
  const {
    width = getTerminalWidth(),
    divider,
    dividerChar = "-",
    align = "center",
    indent: indent2 = 0,
    hangingIndent = 0,
    padding,
    borderTop = true,
    borderBottom = true,
    margin
  } = options;
  const paddingValues = applyPadding(padding, 1);
  const result = [];
  if (borderTop) {
    result.push(divider || line(dividerChar, width));
  }
  for (let i = 0; i < paddingValues.top; i++) {
    result.push("");
  }
  const textLines = formatText(text, {
    width: width - paddingValues.left - paddingValues.right,
    align,
    indent: indent2,
    hangingIndent
  });
  const leftPad = " ".repeat(paddingValues.left);
  const contentLines = textLines.map((line2) => leftPad + line2);
  result.push(...contentLines);
  for (let i = 0; i < paddingValues.bottom; i++) {
    result.push("");
  }
  if (borderBottom) {
    result.push(divider || line(dividerChar, width));
  }
  let finalLines = result;
  if (margin) {
    const marginValues = applyPadding(margin);
    finalLines = applyMargin(result, marginValues);
  }
  return finalLines.join("\n");
}
function box(text, options = {}) {
  const { char = "-", width = getTerminalWidth(), padding, align = "left", rounded = false, title, emoji } = options;
  const paddingValues = applyPadding(padding, 0);
  const result = [];
  const horizontal = rounded ? "─" : char;
  const vertical = rounded ? "│" : "|";
  const topLeft = rounded ? "╭" : "+";
  const topRight = rounded ? "╮" : "+";
  const bottomLeft = rounded ? "╰" : "+";
  const bottomRight = rounded ? "╯" : "+";
  if (title || emoji) {
    const titleText = emoji ? `${emoji} ${title || ""}` : title || "";
    const padding2 = 1;
    const titleSection = ` ${titleText} `;
    const remainingWidth = width - titleSection.length - 2;
    result.push(
      `${topLeft}${horizontal.repeat(padding2)}${titleText}${horizontal.repeat(Math.max(0, remainingWidth - padding2 + 2))}${topRight}`
    );
  } else {
    result.push(`${topLeft}${horizontal.repeat(width - 2)}${topRight}`);
  }
  for (let i = 0; i < paddingValues.top; i++) {
    result.push(`${vertical}${" ".repeat(width - 2)}${vertical}`);
  }
  const contentWidth = width - paddingValues.left - paddingValues.right - 2;
  const lines = text.split("\n");
  for (const contentLine of lines) {
    const leftPad = " ".repeat(paddingValues.left);
    const paddedLine = padText(contentLine, contentWidth, align);
    const rightPad = " ".repeat(paddingValues.right);
    result.push(`${vertical}${leftPad}${paddedLine}${rightPad}${vertical}`);
  }
  for (let i = 0; i < paddingValues.bottom; i++) {
    result.push(`${vertical}${" ".repeat(width - 2)}${vertical}`);
  }
  result.push(`${bottomLeft}${horizontal.repeat(width - 2)}${bottomRight}`);
  return result.join("\n");
}
function paragraph(text, options = {}) {
  return formatText(text, options).join("\n");
}
function heading(text, options = {}) {
  const { level = 1, underline = true, underlineChar = "=", align = "left" } = options;
  const result = [];
  const prefix = level === 1 ? "" : level === 2 ? "## " : "### ";
  const formattedText = prefix + text;
  result.push(align === "center" ? padText(formattedText, getTerminalWidth(), "center") : formattedText);
  if (underline) {
    const underlineLength = formattedText.length;
    result.push(line(underlineChar, underlineLength));
  }
  return result.join("\n");
}
function indent(text, spaces = 2, char = " ") {
  const indentStr = char.repeat(spaces);
  return text.split("\n").map((line2) => indentStr + line2).join("\n");
}
function list(items, options = {}) {
  const { numbered: numbered2 = false, bullet: bullet2 = "•", indent: indentSize = 2, startNumber = 1 } = options;
  return items.map((item, index) => {
    const prefix = numbered2 ? `${startNumber + index}. ` : `${bullet2} `;
    const indentStr = " ".repeat(indentSize);
    return indentStr + prefix + item;
  }).join("\n");
}
function table(headers, rows, options = {}) {
  const { columnWidths, align, border = true, useConsoleTable = false, truncate = false, ellipsis = "..." } = options;
  if (useConsoleTable && typeof console.table === "function") {
    const tableData = rows.map((row) => {
      const obj = {};
      headers.forEach((header, i) => {
        obj[header] = row[i] || "";
      });
      return obj;
    });
    console.table(tableData);
    return "";
  }
  const widths = columnWidths || headers.map((header, i) => {
    const maxContentWidth = Math.max(header.length, ...rows.map((row) => (row[i] || "").length));
    return maxContentWidth + 2;
  });
  const alignments = align || headers.map(() => "left");
  const result = [];
  const formatRow = (cells) => {
    const formattedCells = cells.map((cell, i) => {
      let content = cell;
      const maxWidth = widths[i] || 10;
      if (truncate && content.length > maxWidth - 2) {
        content = truncateWithEllipsis(content, maxWidth - 2, ellipsis);
      }
      return padText(` ${content} `, maxWidth, alignments[i] || "left");
    });
    return border ? `|${formattedCells.join("|")}|` : formattedCells.join(" ");
  };
  if (border) {
    result.push(
      line(
        "-",
        widths.reduce((sum, w) => sum + w, widths.length + 1)
      )
    );
  }
  result.push(formatRow(headers));
  if (border) {
    result.push(
      line(
        "-",
        widths.reduce((sum, w) => sum + w, widths.length + 1)
      )
    );
  }
  for (const row of rows) {
    result.push(formatRow(row));
  }
  if (border) {
    result.push(
      line(
        "-",
        widths.reduce((sum, w) => sum + w, widths.length + 1)
      )
    );
  }
  return result.join("\n");
}
const symbols = {
  // Status symbols
  success: "✅",
  error: "❌",
  warning: "⚠️",
  info: "ℹ️",
  checkmark: "✓",
  cross: "✗",
  // Action symbols
  arrow: "→",
  rightArrow: "→",
  leftArrow: "←",
  upArrow: "↑",
  downArrow: "↓",
  // List symbols
  bullet: "•",
  dash: "-",
  star: "✱",
  circle: "○",
  filledCircle: "●",
  // Emojis
  clipboard: "📋",
  rocket: "🚀",
  fire: "🔥",
  magnifyingGlass: "🔍",
  alert: "🚨",
  package: "📦",
  wrench: "🔧",
  sparkles: "✨"
};
function symbol(name) {
  return symbols[name];
}
const Clout = {
  // Basic functions
  line,
  banner,
  box,
  paragraph,
  heading,
  indent,
  list,
  table,
  // Status and formatting helpers
  statusLine,
  bullet,
  numbered,
  dash,
  child,
  keyValue,
  section,
  // Symbols and emojis
  symbols,
  symbol,
  // Text formatting
  formatText,
  // Utility functions
  getTerminalWidth
};
function handleConflictingOptions(option1, option2, message) {
  console.error(message);
  process.exit(1);
}
function validateVerboseQuietOptions(verbose, quiet) {
  if (verbose && quiet) {
    handleConflictingOptions("--verbose", "--quiet", "Error: --verbose and --quiet options cannot be used together");
  }
}
function parseBooleanOptions(result) {
  return {
    verbose: Boolean(result.verbose),
    quiet: Boolean(result.quiet)
  };
}
function parseCommandArguments(argv, config) {
  return parseArguments(argv, config);
}
function handleCommandHelp(helpText) {
  console.log(helpText);
  process.exit(0);
}
function parseAndValidateCommonOptions(result) {
  const { verbose, quiet } = parseBooleanOptions(result);
  validateVerboseQuietOptions(verbose, quiet);
  return { verbose, quiet };
}
const STAT_HELP_TEXT = `
Usage: orcka stat [options]

Validate the manifest, calculate deterministic tags, and write the HCL output.

Options:
  --file <path>                        Path to orcka configuration file (optional, auto-detected if not provided).
  --dotfile <path>                     Generate GraphViz DOT file for dependency visualization.
  --ascii                              Display ASCII tree visualization of dependencies.
  --verbose, -v                        Output detailed information about the calculation process.
  --quiet, -q                          Suppress all output except errors.
  --help                               Show this help message.

Examples:
  orcka stat
  orcka stat --file docker-sha.yml
  orcka stat --dotfile services.dot
  orcka stat --ascii
  orcka stat --verbose
  orcka stat --quiet
`;
const MODIFY_HELP_TEXT = `
Usage: orcka modify [options]

Modify docker-compose.yml files to use calculated TAG_VER variables.

Options:
  --file <path>                        Path to docker-compose.yml file to modify (required).
  --verbose, -v                        Output detailed information about the modification process.
  --help                              Show this help message.

Examples:
  orcka modify --file docker-compose.yml
  orcka modify --file docker-compose.yml --verbose
`;
const BUILD_HELP_TEXT = `
Usage: orcka build [options]

Build Docker images using docker buildx bake with orcka integration.

Options:
  --file <path>                        Path to orcka configuration file (optional, auto-detected if not provided).
  --target <name>                      Specific target to build (optional, builds all targets if not specified).
  --extra-bake <path>                  Additional bake files to include in the build.
  --extra-compose <path>               Additional compose files to include in the build.
  --skip-validation                    Skip Docker environment validation.
  --pull-policy <value>                pull_policy value to use in generated compose overrides (default: never).
  --verbose, -v                        Output detailed information about the build process.
  --quiet, -q                          Suppress all output except errors.
  --help                              Show this help message.

Examples:
  orcka build
  orcka build --file orcka.yaml
  orcka build --target web-app
  orcka build --extra-bake additional.hcl
  orcka build --pull-policy always
`;
const UP_HELP_TEXT = `
Usage: orcka up [options]

Calculate deterministic tags and start the configured docker-compose runtime.

Options:
  --file <path>                        Path to orcka configuration file (optional, auto-detected if not provided).
  --pull-policy <value>                pull_policy value to use in the generated compose override (default: never).
  --verbose, -v                        Output detailed information about runtime execution.
  --quiet, -q                          Suppress informational output from the runtime stage.
  --help                               Show this help message.

Examples:
  orcka up
  orcka up audit-engine
  orcka up --pull-policy always
`;
const WRITE_HELP_TEXT = `
Usage: orcka write [options]

Generate docker-sha.hcl and a docker-compose override file with pull_policy values.

Options:
  --file <path>          Path to orcka configuration file (auto-detected if not provided).
  --output, -o <path>    Path to write docker-compose override file (default: docker-compose.orcka.override.yml).
  --pull-policy <value>  pull_policy value to apply (default: never).
  --help                 Show this help message.

Examples:
  orcka write
  orcka write --pull-policy always
  orcka write --output compose.override.yml
`;
const WORKFLOW_HELP_TEXT = `
Usage: orcka workflow [options]

Run the fast cached build workflow: stat, registry checks, image validation, bake, and compose up.

Options:
  --file <path>                        Path to orcka configuration file (optional, auto-detected if not provided).
  --ancestry                           Display dependency ancestry output during stat phase.
  --skip-bake                          Skip docker buildx bake execution.
  --skip-up                            Skip docker compose up step.
  --pull-policy <value>                pull_policy value to use in the generated compose override (default: never).
  --verbose, -v                        Output detailed information about each workflow stage.
  --quiet, -q                          Suppress all output except errors.
  --help                               Show this help message.

Examples:
  orcka workflow
  orcka workflow --ancestry
  orcka workflow --skip-bake --skip-up
`;
const RUN_HELP_TEXT = `
Usage: orcka run [services...] [options]

Intelligent workflow that assesses image availability and auto-builds missing images before starting services.
Performs: stat → assess → build (if needed) → up.

Positional Arguments:
  services                             List of services to run (optional, runs all services if not specified).

Options:
  --file <path>                        Path to orcka configuration file (optional, auto-detected if not provided).
  --target <name>                      Specific target to include (optional).
  --skip-build                         Skip automatic image building even if images are missing.
  --detached, -d                       Run services in detached mode (background).
  --pull-policy <value>                pull_policy value to use in the generated compose override (default: never).
  --verbose, -v                        Output detailed information about each step.
  --quiet, -q                          Suppress all output except errors.
  --help                               Show this help message.

Examples:
  orcka run                            # Assess, build if needed, and start all services
  orcka run web api                    # Run specific services
  orcka run --skip-build               # Run without building (fail if images missing)
  orcka run --detached                 # Run in background
`;
const StatCommandConfig = {
  name: "stat",
  args: {
    file: CommonArgs.file,
    help: CommonArgs.help,
    dotfile: {
      names: ["--dotfile"],
      description: "Generate DOT file for visualizing service relationships and rebuild criteria",
      hasValue: true,
      required: false
    },
    ascii: {
      names: ["--ascii"],
      description: "Display ASCII tree visualization of service dependencies and rebuild criteria",
      hasValue: false,
      required: false
    },
    verbose: {
      names: ["--verbose", "-v"],
      description: "Output detailed information about each step of the process",
      hasValue: false,
      required: false
    },
    quiet: {
      names: ["--quiet", "-q"],
      description: "Suppress all output except errors",
      hasValue: false,
      required: false
    }
  },
  examples: [
    "orcka stat",
    "orcka stat --file docker-sha.yml",
    "orcka stat --dotfile services.dot",
    "orcka stat --ascii",
    "orcka stat --verbose",
    "orcka stat --quiet"
  ]
};
const ModifyCommandConfig = {
  name: "modify",
  args: {
    file: {
      names: ["--file", "-f"],
      description: "Path to docker-compose.yml file to modify",
      hasValue: true,
      required: true
    },
    help: CommonArgs.help,
    verbose: {
      names: ["--verbose", "-v"],
      description: "Output detailed information about modifications",
      hasValue: false,
      required: false
    }
  },
  examples: ["orcka modify --file docker-compose.yml", "orcka modify -f docker-compose.yml --verbose"]
};
const BuildCommandConfig = {
  name: "build",
  args: {
    file: CommonArgs.file,
    help: CommonArgs.help,
    target: {
      names: ["--target", "-t"],
      description: "Specific target to build (optional, builds all targets if not specified)",
      hasValue: true,
      required: false
    },
    "extra-bake": {
      names: ["--extra-bake"],
      description: "Additional bake files to include in the build",
      hasValue: true,
      required: false
    },
    "extra-compose": {
      names: ["--extra-compose"],
      description: "Additional compose files to include in the build",
      hasValue: true,
      required: false
    },
    "skip-validation": {
      names: ["--skip-validation"],
      description: "Skip Docker environment validation",
      hasValue: false,
      required: false
    },
    "pull-policy": {
      names: ["--pull-policy"],
      description: "Override pull_policy when generating compose overrides",
      hasValue: true,
      required: false
    },
    verbose: {
      names: ["--verbose", "-v"],
      description: "Output detailed information about the build process",
      hasValue: false,
      required: false
    },
    quiet: {
      names: ["--quiet", "-q"],
      description: "Suppress all output except errors",
      hasValue: false,
      required: false
    }
  },
  examples: [
    "orcka build",
    "orcka build --file orcka.yaml",
    "orcka build --target web-app",
    "orcka build --extra-bake additional.hcl",
    "orcka build --pull-policy always",
    "orcka build --verbose"
  ]
};
const UpCommandConfig = {
  name: "up",
  args: {
    file: CommonArgs.file,
    help: CommonArgs.help,
    "pull-policy": {
      names: ["--pull-policy"],
      description: "Override pull_policy when generating compose overrides",
      hasValue: true,
      required: false
    },
    verbose: {
      names: ["--verbose", "-v"],
      description: "Output detailed information about runtime execution",
      hasValue: false,
      required: false
    },
    quiet: {
      names: ["--quiet", "-q"],
      description: "Suppress informational output from the runtime stage",
      hasValue: false,
      required: false
    }
  },
  examples: ["orcka up", "orcka up audit-engine", "orcka up --pull-policy always"]
};
const WriteCommandConfig = {
  name: "write",
  args: {
    file: CommonArgs.file,
    help: CommonArgs.help,
    output: {
      names: ["--output", "-o"],
      description: "Path to write docker-compose override file",
      hasValue: true,
      required: false
    },
    "pull-policy": {
      names: ["--pull-policy"],
      description: "pull_policy value to apply to each service",
      hasValue: true,
      required: false
    }
  },
  examples: ["orcka write", "orcka write --output compose.override.yml", "orcka write --pull-policy always"]
};
const WorkflowCommandConfig = {
  name: "workflow",
  args: {
    file: CommonArgs.file,
    help: CommonArgs.help,
    ancestry: {
      names: ["--ancestry"],
      description: "Display dependency ancestry as part of the workflow run",
      hasValue: false,
      required: false
    },
    "skip-bake": {
      names: ["--skip-bake"],
      description: "Skip docker buildx bake execution",
      hasValue: false,
      required: false
    },
    "skip-up": {
      names: ["--skip-up"],
      description: "Skip docker compose up after generating overrides",
      hasValue: false,
      required: false
    },
    "pull-policy": {
      names: ["--pull-policy"],
      description: "Override pull_policy when generating compose overrides",
      hasValue: true,
      required: false
    },
    verbose: {
      names: ["--verbose", "-v"],
      description: "Output detailed information about each workflow stage",
      hasValue: false,
      required: false
    },
    quiet: {
      names: ["--quiet", "-q"],
      description: "Suppress informational output from the workflow",
      hasValue: false,
      required: false
    }
  },
  examples: ["orcka workflow", "orcka workflow --ancestry", "orcka workflow --skip-bake --skip-up"]
};
const RunCommandConfig = {
  name: "run",
  args: {
    file: CommonArgs.file,
    help: CommonArgs.help,
    target: {
      names: ["--target"],
      description: "Specific target to include",
      hasValue: true,
      required: false
    },
    "pull-policy": {
      names: ["--pull-policy"],
      description: "Override pull_policy when generating compose overrides",
      hasValue: true,
      required: false
    },
    "skip-build": {
      names: ["--skip-build"],
      description: "Skip automatic image building even if images are missing",
      hasValue: false,
      required: false
    },
    detached: {
      names: ["--detached", "-d"],
      description: "Run services in detached mode (background)",
      hasValue: false,
      required: false
    },
    verbose: {
      names: ["--verbose", "-v"],
      description: "Output detailed information",
      hasValue: false,
      required: false
    },
    quiet: {
      names: ["--quiet", "-q"],
      description: "Suppress informational output",
      hasValue: false,
      required: false
    }
  },
  examples: [
    "orcka run",
    "orcka run web api",
    "orcka run --skip-build",
    "orcka run --detached"
  ]
};
class CyclicDependencyError extends Error {
  constructor(cycles) {
    super(`Cyclic dependencies detected: ${cycles.map((cycle) => cycle.join(" -> ")).join(", ")}`);
    this.cycles = cycles;
    this.name = "CyclicDependencyError";
  }
}
function extractImageAncestry(target) {
  const dependencies = [];
  if (target.contexts) {
    for (const [_contextName, contextValue] of Object.entries(target.contexts)) {
      if (typeof contextValue === "string" && contextValue.startsWith("target:")) {
        const targetName = contextValue.substring("target:".length);
        dependencies.push(targetName);
      }
    }
  }
  return dependencies;
}
function extractRuntimeDependencies(target) {
  const dependencies = [];
  if (target.depends_on) {
    dependencies.push(...target.depends_on);
  }
  return dependencies;
}
function buildImageAncestryTree(targets) {
  const nodes = /* @__PURE__ */ new Map();
  for (const [targetName, target] of Object.entries(targets)) {
    const dependencies = extractImageAncestry(target);
    nodes.set(targetName, {
      serviceName: targetName,
      dependencies,
      dependents: [],
      level: 0
    });
  }
  for (const [serviceName, node] of nodes) {
    for (const dep of node.dependencies) {
      const depNode = nodes.get(dep);
      if (depNode) {
        depNode.dependents.push(serviceName);
      }
    }
  }
  const cycles = detectCycles(nodes);
  if (cycles.length > 0) {
    throw new CyclicDependencyError(cycles);
  }
  const levels = calculateLevels(nodes);
  for (const [serviceName, level] of levels) {
    const node = nodes.get(serviceName);
    if (node) {
      node.level = level;
    }
  }
  const roots = [];
  const leaves = [];
  for (const [serviceName, node] of nodes) {
    if (node.dependencies.length === 0) {
      roots.push(serviceName);
    }
    if (node.dependents.length === 0) {
      leaves.push(serviceName);
    }
  }
  return {
    nodes,
    roots,
    leaves,
    cycles
  };
}
function detectCycles(nodes) {
  const visited = /* @__PURE__ */ new Set();
  const recursionStack = /* @__PURE__ */ new Set();
  const cycles = [];
  function dfs(serviceName, path) {
    if (recursionStack.has(serviceName)) {
      const cycleStart = path.indexOf(serviceName);
      const cycle = path.slice(cycleStart).concat(serviceName);
      cycles.push(cycle);
      return;
    }
    if (visited.has(serviceName)) {
      return;
    }
    visited.add(serviceName);
    recursionStack.add(serviceName);
    const node = nodes.get(serviceName);
    if (node) {
      for (const dep of node.dependencies) {
        if (nodes.has(dep)) {
          dfs(dep, [...path, serviceName]);
        }
      }
    }
    recursionStack.delete(serviceName);
  }
  for (const serviceName of nodes.keys()) {
    if (!visited.has(serviceName)) {
      dfs(serviceName, []);
    }
  }
  return cycles;
}
function calculateLevels(nodes) {
  const levels = /* @__PURE__ */ new Map();
  const visited = /* @__PURE__ */ new Set();
  function calculateLevel(serviceName) {
    const existingLevel = levels.get(serviceName);
    if (existingLevel !== void 0) {
      return existingLevel;
    }
    if (visited.has(serviceName)) {
      return 0;
    }
    visited.add(serviceName);
    const node = nodes.get(serviceName);
    if (!node || node.dependencies.length === 0) {
      levels.set(serviceName, 0);
      return 0;
    }
    let maxDepLevel = -1;
    for (const dep of node.dependencies) {
      if (nodes.has(dep)) {
        const depLevel = calculateLevel(dep);
        maxDepLevel = Math.max(maxDepLevel, depLevel);
      }
    }
    const level = maxDepLevel + 1;
    levels.set(serviceName, level);
    return level;
  }
  for (const serviceName of nodes.keys()) {
    calculateLevel(serviceName);
  }
  return levels;
}
function getServicesInDependencyOrder(tree) {
  const servicesByLevel = /* @__PURE__ */ new Map();
  for (const [serviceName, node] of tree.nodes) {
    const level = node.level;
    let services = servicesByLevel.get(level);
    if (!services) {
      services = [];
      servicesByLevel.set(level, services);
    }
    services.push(serviceName);
  }
  const result = [];
  const sortedLevels = Array.from(servicesByLevel.keys()).sort((a, b) => a - b);
  for (const level of sortedLevels) {
    const services = servicesByLevel.get(level);
    if (services) {
      result.push(...services.sort());
    }
  }
  return result;
}
function buildRuntimeDependencyTree(targets) {
  const nodes = /* @__PURE__ */ new Map();
  for (const [targetName, target] of Object.entries(targets)) {
    const dependencies = extractRuntimeDependencies(target);
    nodes.set(targetName, {
      serviceName: targetName,
      dependencies,
      dependents: [],
      level: 0
    });
  }
  for (const [serviceName, node] of nodes) {
    for (const dependency of node.dependencies) {
      const dependencyNode = nodes.get(dependency);
      if (dependencyNode) {
        dependencyNode.dependents.push(serviceName);
      }
    }
  }
  const visited = /* @__PURE__ */ new Set();
  const recursionStack = /* @__PURE__ */ new Set();
  const cycles = [];
  function detectCycles2(serviceName, path) {
    if (recursionStack.has(serviceName)) {
      const cycleStart = path.indexOf(serviceName);
      const cycle = path.slice(cycleStart).concat([serviceName]);
      cycles.push(cycle);
      return;
    }
    if (visited.has(serviceName)) {
      return;
    }
    visited.add(serviceName);
    recursionStack.add(serviceName);
    const node = nodes.get(serviceName);
    if (node) {
      for (const dependency of node.dependencies) {
        detectCycles2(dependency, [...path, serviceName]);
      }
    }
    recursionStack.delete(serviceName);
  }
  for (const serviceName of nodes.keys()) {
    if (!visited.has(serviceName)) {
      detectCycles2(serviceName, []);
    }
  }
  if (cycles.length > 0) {
    throw new CyclicDependencyError(cycles);
  }
  const calculateLevels2 = () => {
    const roots2 = [];
    const leaves2 = [];
    for (const [serviceName, node] of nodes) {
      if (node.dependencies.length === 0) {
        roots2.push(serviceName);
      }
      if (node.dependents.length === 0) {
        leaves2.push(serviceName);
      }
    }
    return { roots: roots2, leaves: leaves2 };
  };
  const { roots, leaves } = calculateLevels2();
  return {
    nodes,
    roots,
    leaves,
    cycles
  };
}
function buildDependencyTree(targets) {
  return buildRuntimeDependencyTree(targets);
}
function collectDependencyClosure(tree, seeds) {
  const result = /* @__PURE__ */ new Set();
  const stack = [];
  for (const seed of seeds) {
    stack.push(seed);
  }
  while (stack.length > 0) {
    const current = stack.pop();
    if (!current || result.has(current)) {
      continue;
    }
    result.add(current);
    const node = tree.nodes.get(current);
    if (!node) {
      continue;
    }
    for (const dependency of node.dependencies) {
      if (!result.has(dependency)) {
        stack.push(dependency);
      }
    }
  }
  return result;
}
function normaliseBasename(value) {
  if (!value) {
    return void 0;
  }
  const trimmed = value.trim();
  if (trimmed.length === 0) {
    return void 0;
  }
  return node_path.basename(trimmed);
}
function getOrckaDirectory(projectContext) {
  return node_path.resolve(projectContext, ".orcka");
}
function ensureOrckaDirectory(projectContext) {
  const directory = getOrckaDirectory(projectContext);
  if (!node_fs.existsSync(directory)) {
    node_fs.mkdirSync(directory, { recursive: true });
  }
  return directory;
}
function deriveTagsFileName(project) {
  if (typeof project.write === "string") {
    const fromString = normaliseBasename(project.write);
    if (fromString) {
      return fromString;
    }
  }
  if (project.write && typeof project.write === "object") {
    const fromConfig = normaliseBasename(project.write.tags);
    if (fromConfig) {
      return fromConfig;
    }
  }
  const baseName = project.name?.trim() || "orcka";
  return `${baseName}.tags.hcl`;
}
function deriveComposeOverrideFileName(project) {
  if (project?.write && typeof project.write === "object") {
    const fromConfig = normaliseBasename(project.write.compose);
    if (fromConfig) {
      return fromConfig;
    }
  }
  return "docker-compose.orcka.override.yml";
}
function resolveTagsOutputPath(projectContext, project) {
  const directory = getOrckaDirectory(projectContext);
  return node_path.join(directory, deriveTagsFileName(project));
}
function resolveComposeOverridePath(projectContext, project) {
  const directory = getOrckaDirectory(projectContext);
  const fileName = deriveComposeOverrideFileName(project);
  return node_path.join(directory, fileName);
}
class DockerBakeExecutor {
  logger;
  constructor(logger) {
    this.logger = logger;
  }
  /**
   * Execute docker buildx bake command with orcka configuration
   */
  async executeBake(options) {
    try {
      const config = await this.parseOrckaConfig(options.configFile);
      const bakeCommand = this.buildBakeCommand(config, options);
      this.logger.verbose(`🏗️  Executing: ${bakeCommand.join(" ")}`);
      return await this.runBakeCommand(bakeCommand, options);
    } catch (error) {
      return {
        success: false,
        exitCode: 1,
        error: `Failed to execute bake: ${error instanceof Error ? error.message : String(error)}`
      };
    }
  }
  /**
   * Parse orcka configuration file
   */
  async parseOrckaConfig(configFile) {
    const { parse: yamlParse } = await import("yaml");
    const { readFileSync } = await import("node:fs");
    if (!node_fs.existsSync(configFile)) {
      throw new Error(`Configuration file not found: ${configFile}`);
    }
    const content = readFileSync(configFile, "utf-8");
    if (configFile.endsWith(".hcl")) {
      throw new Error("HCL config files are temporarily not supported. Please use YAML format.");
    } else {
      return yamlParse(content);
    }
  }
  /**
   * Build docker buildx bake command arguments
   */
  buildBakeCommand(config, options) {
    const command = ["docker", "buildx", "bake"];
    const configDir = node_path.dirname(options.configFile);
    const projectConfig = config.project ?? { name: "orcka", bake: [] };
    const projectContext = node_path.resolve(configDir, projectConfig.context ?? ".");
    if (projectConfig.bake) {
      for (const bakeFile of projectConfig.bake) {
        const resolvedPath = node_path.resolve(projectContext, bakeFile);
        if (node_fs.existsSync(resolvedPath)) {
          command.push("--file", resolvedPath);
          this.logger.verbose(`📄 Using bake file: ${resolvedPath}`);
        } else {
          this.logger.warn(`⚠️  Bake file not found: ${resolvedPath}`);
        }
      }
    }
    if (options.extraBakeFiles) {
      for (const extraFile of options.extraBakeFiles) {
        const resolvedPath = node_path.resolve(extraFile);
        if (node_fs.existsSync(resolvedPath)) {
          command.push("--file", resolvedPath);
          this.logger.verbose(`📄 Using extra bake file: ${resolvedPath}`);
        } else {
          this.logger.warn(`⚠️  Extra bake file not found: ${resolvedPath}`);
        }
      }
    }
    if (options.extraComposeFiles) {
      for (const extraFile of options.extraComposeFiles) {
        const resolvedPath = node_path.resolve(extraFile);
        if (node_fs.existsSync(resolvedPath)) {
          command.push("--file", resolvedPath);
          this.logger.verbose(`📄 Using extra compose file: ${resolvedPath}`);
        } else {
          this.logger.warn(`⚠️  Extra compose file not found: ${resolvedPath}`);
        }
      }
    }
    const generatedHclPath = resolveTagsOutputPath(projectContext, projectConfig);
    if (node_fs.existsSync(generatedHclPath)) {
      command.push("--file", generatedHclPath);
      this.logger.verbose(`📄 Using generated HCL: ${generatedHclPath}`);
    } else {
      this.logger.warn(`⚠️  Generated HCL file not found: ${generatedHclPath}`);
    }
    const targets = options.targets && options.targets.length > 0 ? options.targets : options.target ? [options.target] : [];
    if (options.generatedServices) {
      const servicesWithComposeTags = options.generatedServices.filter((s) => s.composeTag && s.composeReference);
      for (const service of servicesWithComposeTags) {
        const tagsValue = `${service.imageReference},${service.composeReference}`;
        command.push("--set", `${service.name}.tags=${tagsValue}`);
        this.logger.verbose(`🏷️  Dual tagging ${service.name}: ${service.imageReference}, ${service.composeReference}`);
      }
      if (servicesWithComposeTags.length > 0) {
        this.logger.verbose(`📝 Applied dual tagging to ${servicesWithComposeTags.length} services`);
      }
    }
    if (targets.length > 0) {
      for (const target of targets) {
        command.push(target);
      }
      this.logger.verbose(`🎯 Building targets: ${targets.join(", ")}`);
    } else {
      this.logger.verbose(`🎯 Building all targets`);
    }
    return command;
  }
  /**
   * Execute the docker buildx bake command
   */
  async runBakeCommand(command, options) {
    return new Promise((resolve2) => {
      const [cmd, ...args] = command;
      this.logger.info(`🚀 Starting Docker build...`);
      const child2 = node_child_process.spawn(cmd, args, {
        stdio: options.quiet ? "pipe" : "inherit",
        env: process.env
      });
      let output = "";
      let error = "";
      if (options.quiet) {
        child2.stdout?.on("data", (data) => {
          output += data.toString();
        });
        child2.stderr?.on("data", (data) => {
          error += data.toString();
        });
      }
      child2.on("close", (code) => {
        const success = code === 0;
        if (success) {
          this.logger.success(`✅ Docker build completed successfully`);
        } else {
          this.logger.error(`❌ Docker build failed with exit code ${code}`);
        }
        resolve2({
          success,
          exitCode: code || 0,
          output: output || void 0,
          error: error || void 0
        });
      });
      child2.on("error", (err) => {
        this.logger.error(`❌ Failed to start docker buildx bake: ${err.message}`);
        resolve2({
          success: false,
          exitCode: 1,
          error: err.message
        });
      });
    });
  }
  /**
   * Check if docker buildx bake is available
   */
  static async checkBakeAvailability() {
    try {
      node_child_process.execSync("docker buildx bake --help", {
        stdio: "pipe",
        timeout: 5e3
      });
      return { available: true };
    } catch (error) {
      return {
        available: false,
        error: `docker buildx bake not available: ${error instanceof Error ? error.message : String(error)}`
      };
    }
  }
}
async function executeBake(options, logger) {
  const executor = new DockerBakeExecutor(logger);
  return executor.executeBake(options);
}
function runComposeUp({
  composeFiles,
  quiet,
  services,
  detached
}) {
  if (composeFiles.length === 0) {
    throw new Error("At least one compose file must be provided");
  }
  const stdio = quiet ? "pipe" : "inherit";
  const fileArgs = composeFiles.map((file) => `--file ${file}`).join(" ");
  const detachedFlag = detached ? " -d" : "";
  const servicesArgs = services && services.length > 0 ? ` ${services.join(" ")}` : "";
  node_child_process.execSync(`docker compose ${fileArgs} up${detachedFlag}${servicesArgs}`, {
    stdio,
    env: process.env
  });
}
const MINIMUM_VERSIONS = {
  docker: "20.10.0",
  buildx: "0.8.0",
  containerd: "1.6.0"
};
class DockerEnvValidator {
  logger;
  constructor(logger) {
    this.logger = logger;
  }
  /**
   * Validate the complete Docker environment
   */
  async validateEnvironment() {
    const errors = [];
    const warnings = [];
    let environment;
    this.logger?.verbose("🐳 Validating Docker environment...");
    try {
      const dockerVersion = await this.getDockerVersion();
      const dockerRunning = await this.isDockerRunning();
      const buildxDetection = await this.detectBuildx();
      const buildxVersion = buildxDetection.version;
      const buildxAvailable = buildxDetection.available;
      const containerdVersion = await this.getContainerdVersion();
      const containerdAvailable = containerdVersion !== null;
      environment = {
        docker: dockerVersion,
        buildx: buildxVersion || void 0,
        containerd: containerdVersion || void 0,
        dockerRunning,
        buildxAvailable,
        containerdAvailable
      };
      if (!this.isVersionSufficient(dockerVersion.version, MINIMUM_VERSIONS.docker)) {
        errors.push(`Docker version ${dockerVersion.version} is below minimum required ${MINIMUM_VERSIONS.docker}`);
      }
      if (buildxVersion && buildxVersion.version !== "unknown" && !this.isVersionSufficient(buildxVersion.version, MINIMUM_VERSIONS.buildx)) {
        errors.push(
          `Docker Buildx version ${buildxVersion.version} is below minimum required ${MINIMUM_VERSIONS.buildx}`
        );
      }
      if (containerdVersion && !this.isVersionSufficient(containerdVersion.version, MINIMUM_VERSIONS.containerd)) {
        warnings.push(
          `containerd version ${containerdVersion.version} is below recommended ${MINIMUM_VERSIONS.containerd}`
        );
      }
      if (!dockerRunning) {
        errors.push("Docker daemon is not running. Please start Docker.");
      }
      if (!buildxAvailable) {
        errors.push("Docker Buildx is not available. orcka requires Buildx for multi-platform builds.");
      }
      if (!containerdAvailable) {
        warnings.push("containerd is not available. This may affect some advanced Docker features.");
      }
      if (this.logger) {
        this.logEnvironmentInfo(environment);
      }
    } catch (error) {
      errors.push(`Failed to validate Docker environment: ${error instanceof Error ? error.message : String(error)}`);
    }
    const valid = errors.length === 0;
    if (valid) {
      this.logger?.verbose("✅ Docker environment validation passed");
    } else {
      this.logger?.verbose("❌ Docker environment validation failed");
    }
    return {
      valid,
      environment,
      errors,
      warnings
    };
  }
  /**
   * Get Docker version information
   */
  async getDockerVersion() {
    try {
      const output = node_child_process.execSync("docker version --format json", {
        encoding: "utf-8",
        timeout: 5e3
      });
      const versionInfo = JSON.parse(output);
      const client = versionInfo.Client;
      return {
        version: client.Version,
        apiVersion: client.ApiVersion,
        gitCommit: client.GitCommit,
        buildTime: client.BuildTime
      };
    } catch (error) {
      throw new Error(`Failed to get Docker version: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  /**
   * Check if Docker daemon is running
   */
  async isDockerRunning() {
    try {
      node_child_process.execSync("docker info", {
        encoding: "utf-8",
        timeout: 5e3,
        stdio: "pipe"
      });
      return true;
    } catch {
      return false;
    }
  }
  /**
   * Get Docker Buildx version information
   */
  async detectBuildx() {
    const commands = ['docker buildx version --format "{{json .}}"', "docker buildx version"];
    let fallbackOutput = null;
    for (const command of commands) {
      try {
        const output = node_child_process.execSync(command, {
          encoding: "utf-8",
          timeout: 5e3,
          stdio: "pipe"
        });
        const parsed = this.parseBuildxVersionOutput(output);
        if (parsed) {
          return { version: parsed, available: true };
        }
        fallbackOutput = output;
      } catch {
      }
    }
    if (fallbackOutput && fallbackOutput.trim().length > 0) {
      return { version: { version: "unknown" }, available: true };
    }
    return { version: null, available: false };
  }
  parseBuildxVersionOutput(output) {
    const trimmed = output.trim();
    if (!trimmed) {
      return null;
    }
    if (trimmed.startsWith("{")) {
      try {
        const data = JSON.parse(trimmed);
        const version = data.Version ?? data.version ?? data.BuildxVersion ?? data.buildxVersion;
        if (typeof version === "string" && version.length > 0) {
          return {
            version: version.replace(/^v/, ""),
            gitCommit: data.GitCommit ?? data.gitCommit ?? data.BuildxCommit ?? data.buildxCommit ?? data.Revision ?? data.revision
          };
        }
      } catch {
      }
    }
    const versionMatch = trimmed.match(/v?(\d+\.\d+\.\d+(?:-[\w.+]+)?)/);
    if (versionMatch) {
      const commitMatch = trimmed.match(/\b([a-f0-9]{7,})\b/);
      return {
        version: versionMatch[1],
        gitCommit: commitMatch?.[1]
      };
    }
    return null;
  }
  /**
   * Get containerd version information
   */
  async getContainerdVersion() {
    try {
      const output = node_child_process.execSync("containerd --version", {
        encoding: "utf-8",
        timeout: 5e3,
        stdio: "pipe"
      });
      const match = output.match(/containerd.*?v(\d+\.\d+\.\d+(?:-\w+)?)\s+([a-f0-9]+)?/);
      if (match) {
        return {
          version: match[1],
          revision: match[2]
        };
      }
    } catch {
      try {
        const dockerVersionOutput = node_child_process.execSync("docker version", {
          encoding: "utf-8",
          timeout: 5e3,
          stdio: "pipe"
        });
        const lines = dockerVersionOutput.split("\n");
        let inContainerdSection = false;
        for (const line2 of lines) {
          if (line2.trim().startsWith("containerd:")) {
            inContainerdSection = true;
            continue;
          }
          if (inContainerdSection && line2.includes("Version:")) {
            const versionMatch = line2.match(/Version:\s+(\d+\.\d+\.\d+(?:-\w+)?)/);
            if (versionMatch) {
              return {
                version: versionMatch[1],
                revision: void 0
              };
            }
          }
          if (inContainerdSection && line2.match(/^\s*[a-z-]+:$/i)) {
            break;
          }
        }
      } catch {
      }
    }
    return null;
  }
  /**
   * Compare version strings (semantic versioning)
   */
  isVersionSufficient(current, minimum) {
    const currentParts = current.replace(/^v/, "").split(".").map(Number);
    const minimumParts = minimum.split(".").map(Number);
    for (let i = 0; i < Math.max(currentParts.length, minimumParts.length); i++) {
      const currentPart = currentParts[i] || 0;
      const minimumPart = minimumParts[i] || 0;
      if (currentPart > minimumPart) return true;
      if (currentPart < minimumPart) return false;
    }
    return true;
  }
  /**
   * Log environment information
   */
  logEnvironmentInfo(env) {
    if (!this.logger) return;
    this.logger.verbose("🐳 Docker Environment:");
    this.logger.verbose(`  Docker: ${env.docker.version} (API: ${env.docker.apiVersion})`);
    this.logger.verbose(`  Docker Running: ${env.dockerRunning ? "✅" : "❌"}`);
    if (env.buildx) {
      this.logger.verbose(`  Buildx: ${env.buildx.version} ${env.buildxAvailable ? "✅" : "❌"}`);
    } else {
      this.logger.verbose(`  Buildx: Not available ❌`);
    }
    if (env.containerd) {
      this.logger.verbose(`  containerd: ${env.containerd.version} ${env.containerdAvailable ? "✅" : "⚠️"}`);
    } else {
      this.logger.verbose(`  containerd: Not available ⚠️`);
    }
  }
}
async function validateDockerEnvironment(logger) {
  const validator = new DockerEnvValidator(logger);
  return validator.validateEnvironment();
}
function parseRegistryFromImage(imageRef) {
  const parts = imageRef.split("/");
  if (parts.length === 1) {
    return "docker.io";
  }
  const firstPart = parts[0];
  if (firstPart.includes(".") || firstPart.includes(":")) {
    return firstPart;
  }
  return "docker.io";
}
function checkRegistryAuth(registryName) {
  try {
    const configPath = getDockerConfigPath();
    if (!node_fs.existsSync(configPath)) {
      return false;
    }
    const configContent = node_fs.readFileSync(configPath, "utf-8");
    const config = JSON.parse(configContent);
    if (config.auths && typeof config.auths === "object") {
      const registryVariations = [
        registryName,
        `https://${registryName}`,
        `http://${registryName}`
      ];
      if (registryName === "docker.io") {
        registryVariations.push("https://index.docker.io/v1/");
        registryVariations.push("https://index.docker.io/v2/");
      }
      for (const variation of registryVariations) {
        if (variation in config.auths) {
          const authEntry = config.auths[variation];
          if (authEntry && (authEntry.auth || authEntry.username)) {
            return true;
          }
        }
      }
    }
    if (config.credsStore || config.credHelpers) {
      return true;
    }
    return false;
  } catch {
    return false;
  }
}
function checkRegistryAccessibility(registryName) {
  try {
    const probeImage = getRegistryProbeImage(registryName);
    node_child_process.execSync(`docker manifest inspect ${probeImage}`, {
      stdio: "pipe",
      timeout: 5e3
    });
    return { accessible: true };
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    if (errorMsg.includes("unauthorized") || errorMsg.includes("401")) {
      return { accessible: false, error: "unauthorized" };
    }
    if (errorMsg.includes("not found") || errorMsg.includes("404")) {
      return { accessible: false, error: "not found" };
    }
    if (errorMsg.includes("timeout") || errorMsg.includes("connection")) {
      return { accessible: false, error: "connection failed" };
    }
    return { accessible: false, error: "unknown" };
  }
}
function getRegistryProbeImage(registryName) {
  const probes = {
    "docker.io": "docker.io/library/hello-world:latest",
    "ghcr.io": "ghcr.io/github/super-linter:latest",
    "gcr.io": "gcr.io/google-containers/pause:latest",
    "quay.io": "quay.io/prometheus/node-exporter:latest"
  };
  return probes[registryName] || `${registryName}/probe:latest`;
}
function getDockerConfigPath() {
  const dockerConfig = process.env.DOCKER_CONFIG;
  if (dockerConfig) {
    return node_path.join(dockerConfig, "config.json");
  }
  return node_path.join(node_os.homedir(), ".docker", "config.json");
}
function checkImageLocal(imageRef) {
  try {
    node_child_process.execSync(`docker image inspect ${imageRef}`, {
      stdio: "pipe",
      timeout: 2e3
    });
    return true;
  } catch {
    return false;
  }
}
function analyzeRegistries(imageReferences) {
  const errors = [];
  const registryMap = /* @__PURE__ */ new Map();
  for (const imageRef of imageReferences) {
    const registryName = parseRegistryFromImage(imageRef);
    if (!registryMap.has(registryName)) {
      registryMap.set(registryName, { images: [], localImages: [] });
    }
    const registryData = registryMap.get(registryName);
    registryData.images.push(imageRef);
    if (checkImageLocal(imageRef)) {
      registryData.localImages.push(imageRef);
    }
  }
  const registries = [];
  for (const [registryName, data] of registryMap.entries()) {
    try {
      const authenticated = checkRegistryAuth(registryName);
      const accessCheck = checkRegistryAccessibility(registryName);
      registries.push({
        name: registryName,
        authenticated,
        accessible: accessCheck.accessible,
        imageCount: data.images.length,
        localCount: data.localImages.length,
        error: accessCheck.error
      });
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      errors.push(`Failed to analyze registry ${registryName}: ${errorMsg}`);
      registries.push({
        name: registryName,
        authenticated: false,
        accessible: false,
        imageCount: data.images.length,
        localCount: data.localImages.length,
        error: errorMsg
      });
    }
  }
  registries.sort((a, b) => b.imageCount - a.imageCount);
  const totalImages = imageReferences.length;
  const totalLocal = registries.reduce((sum, reg) => sum + reg.localCount, 0);
  return {
    registries,
    totalImages,
    totalLocal,
    errors
  };
}
function formatRegistryStatus(info) {
  if (info.accessible) {
    return info.authenticated ? "✅ authenticated" : "🔓 accessible";
  }
  if (info.error === "unauthorized") {
    return "🔒 unauthorized";
  }
  if (info.error === "not found") {
    return "❓ not found";
  }
  if (info.error === "connection failed") {
    return "⚠️ unreachable";
  }
  return "❌ inaccessible";
}
class Logger {
  options;
  constructor(options = { verbose: false, quiet: false }) {
    this.options = options;
  }
  /**
   * Log an error message (always shown unless quiet mode conflicts)
   */
  error(message) {
    console.error(Clout.statusLine("error", message));
  }
  /**
   * Log an info message (shown unless quiet mode is enabled)
   */
  info(message) {
    if (!this.options.quiet) {
      console.log(Clout.statusLine("info", message));
    }
  }
  /**
   * Log a success message (shown unless quiet mode is enabled)
   */
  success(message) {
    if (!this.options.quiet) {
      console.log(Clout.statusLine("success", message));
    }
  }
  /**
   * Log a verbose message (only shown in verbose mode)
   */
  verbose(message) {
    if (this.options.verbose && !this.options.quiet) {
      console.log(`🔍 ${message}`);
    }
  }
  /**
   * Log a warning message (shown unless quiet mode is enabled)
   */
  warn(message) {
    if (!this.options.quiet) {
      console.warn(Clout.statusLine("warning", message));
    }
  }
  /**
   * Log service generation summary
   */
  logServiceSummary(services) {
    if (this.options.quiet) return;
    if (services.length === 0) {
      this.info("No services with calculate_on criteria found");
      return;
    }
    this.info(`Generated ${services.length} service tag${services.length === 1 ? "" : "s"}:`);
    const sortedServices = [...services].sort((a, b) => a.varName.localeCompare(b.varName));
    const maxVarNameLength = Math.min(66, Math.max(...sortedServices.map((s) => s.varName.length)));
    for (const service of sortedServices) {
      const displayVarName = service.varName.length > 66 ? `${service.varName.substring(0, 63)}...` : service.varName;
      const padding = maxVarNameLength - displayVarName.length;
      const spaces = " ".repeat(Math.max(0, padding));
      console.log(` ${displayVarName}:${spaces} "${service.imageTag}"`);
    }
  }
  /**
   * Log detailed service processing information
   */
  logServiceProcessing(serviceName, step, details) {
    if (!this.options.verbose || this.options.quiet) return;
    const message = details ? `${step}: ${details}` : step;
    console.log(`🔍 [${serviceName}] ${message}`);
  }
  /**
   * Update logger options
   */
  updateOptions(options) {
    this.options = { ...this.options, ...options };
  }
}
function displayRegistrySection(analysis) {
  if (analysis.registries.length === 0) {
    return;
  }
  console.log("");
  console.log("🌐 Docker Registries:");
  console.log("");
  console.log(`  Total: ${analysis.totalImages} images across ${analysis.registries.length} ${analysis.registries.length === 1 ? "registry" : "registries"}`);
  console.log(`  Local: ${analysis.totalLocal} images (${Math.round(analysis.totalLocal / analysis.totalImages * 100)}% available locally)`);
  console.log("");
  const headers = ["Registry", "Status", "Images", "Local"];
  const rows = analysis.registries.map((reg) => [
    reg.name,
    formatRegistryStatus(reg),
    reg.imageCount.toString(),
    `${reg.localCount}/${reg.imageCount}`
  ]);
  const table2 = Clout.table(headers, rows, {
    columnWidths: [30, 20, 8, 12],
    align: ["left", "left", "right", "right"],
    border: false,
    truncate: true
  });
  console.log(table2);
  const inaccessibleRegistries = analysis.registries.filter((r) => !r.accessible);
  if (inaccessibleRegistries.length > 0) {
    console.log("");
    console.log("  ⚠️  Registry Access Issues:");
    for (const reg of inaccessibleRegistries) {
      const reason = reg.error || "unknown";
      console.log(`    • ${reg.name}: ${reason}`);
      if (reason === "unauthorized" && !reg.authenticated) {
        console.log(`      → Run: docker login ${reg.name}`);
      }
    }
  }
  if (analysis.errors.length > 0) {
    console.log("");
    console.log("  ⚠️  Registry Analysis Errors:");
    for (const error of analysis.errors) {
      console.log(`    • ${error}`);
    }
  }
}
class HclParser {
  static isHclParsingEnabled = true;
  /**
   * Parse an HCL file and return structured data
   *
   * @param filePath - Path to the HCL file
   * @param fileName - Optional filename for metadata (used by HCL parser)
   * @param options - Parsing options
   * @returns Promise resolving to parse result
   */
  static async parseHclFile(filePath, fileName, options = {}) {
    if (!node_fs.existsSync(filePath)) {
      return {
        success: false,
        error: `HCL file not found: ${filePath}`
      };
    }
    try {
      const content = node_fs.readFileSync(filePath, "utf-8");
      return await HclParser.parseHclContent(content, fileName || filePath, options);
    } catch (error) {
      return {
        success: false,
        error: `Failed to read HCL file: ${error instanceof Error ? error.message : String(error)}`
      };
    }
  }
  /**
   * Parse HCL content string and return structured data
   *
   * @param content - HCL content as string
   * @param fileName - Filename for metadata (used by HCL parser)
   * @param options - Parsing options
   * @returns Promise resolving to parse result
   */
  static async parseHclContent(_content, fileName, options = {}) {
    const { useFallback = true, silent = false } = options;
    if (HclParser.isHclParsingEnabled) {
      try {
        const parsedHcl = await hcl2json.parse(fileName, _content);
        return {
          success: true,
          data: HclParser.normalizeHclData(parsedHcl)
        };
      } catch (error) {
        if (!silent) {
          console.warn(`HCL parsing failed for ${fileName}: ${error instanceof Error ? error.message : String(error)}`);
        }
        if (useFallback) {
          return HclParser.getFallbackResult(fileName, silent);
        }
        return {
          success: false,
          error: `HCL parsing failed: ${error instanceof Error ? error.message : String(error)}`
        };
      }
    } else {
      if (useFallback) {
        return HclParser.getFallbackResult(fileName, silent);
      }
      return {
        success: false,
        error: "HCL parsing is disabled due to WASM dependency issues"
      };
    }
  }
  /**
   * Parse multiple HCL files and return a map of results
   *
   * @param filePaths - Array of HCL file paths
   * @param options - Parsing options
   * @returns Promise resolving to map of filename to parse result
   */
  static async parseMultipleHclFiles(filePaths, options = {}) {
    const results = /* @__PURE__ */ new Map();
    for (const filePath of filePaths) {
      const fileName = filePath.split("/").pop() || filePath;
      const result = await HclParser.parseHclFile(filePath, fileName, options);
      results.set(fileName, result);
    }
    return results;
  }
  /**
   * Parse HCL files from a directory with a specific pattern
   *
   * @param contextDir - Directory to search in
   * @param fileNames - Array of filenames to parse
   * @param options - Parsing options
   * @returns Promise resolving to map of filename to parse result
   */
  static async parseHclFilesFromContext(contextDir, fileNames, options = {}) {
    const results = /* @__PURE__ */ new Map();
    for (const fileName of fileNames) {
      const filePath = node_path.resolve(contextDir, fileName);
      const result = await HclParser.parseHclFile(filePath, fileName, options);
      results.set(fileName, result);
    }
    return results;
  }
  /**
   * Check if HCL parsing is currently enabled
   */
  static isParsingEnabled() {
    return HclParser.isHclParsingEnabled;
  }
  /**
   * Enable or disable HCL parsing (for testing or when WASM issues are resolved)
   */
  static setParsingEnabled(enabled) {
    HclParser.isHclParsingEnabled = enabled;
  }
  /**
   * Normalize HCL parser output to consistent format
   *
   * The HCL parser sometimes returns targets as arrays, this normalizes the structure
   */
  static normalizeHclData(parsedHcl) {
    const bakeConfig = {};
    if (parsedHcl?.target) {
      bakeConfig.target = {};
      for (const [targetName, targetConfig] of Object.entries(parsedHcl.target)) {
        if (targetName.includes(")") || targetName.includes("(")) {
          continue;
        }
        const targetData = Array.isArray(targetConfig) ? targetConfig[0] : targetConfig;
        if (targetData && typeof targetData === "object") {
          bakeConfig.target[targetName] = targetData;
        }
      }
    }
    if (parsedHcl?.variable) {
      bakeConfig.variable = {};
      for (const [variableName, variableConfig] of Object.entries(parsedHcl.variable)) {
        if (variableName.includes(")") || variableName.includes("(")) {
          continue;
        }
        const variableData = Array.isArray(variableConfig) ? variableConfig[0] : variableConfig;
        if (variableData && typeof variableData === "object") {
          bakeConfig.variable[variableName] = variableData;
        }
      }
    }
    return bakeConfig;
  }
  /**
   * Provide fallback result when HCL parsing is disabled
   */
  static getFallbackResult(fileName, silent) {
    if (!silent) {
      console.warn(`HCL parsing disabled for ${fileName}, using empty fallback`);
    }
    return {
      success: true,
      data: { target: {} }
    };
  }
}
function extractBakeConfigs(parseResults) {
  const bakeConfigs = /* @__PURE__ */ new Map();
  for (const [fileName, result] of parseResults) {
    if (result.success && result.data) {
      bakeConfigs.set(fileName, result.data);
    } else {
      bakeConfigs.set(fileName, { target: {} });
    }
  }
  return bakeConfigs;
}
function safeReadFile(filePath) {
  try {
    if (!node_fs.existsSync(filePath)) {
      return {
        success: false,
        error: "File not found",
        path: filePath
      };
    }
    const content = node_fs.readFileSync(filePath, "utf-8");
    return {
      success: true,
      data: content
    };
  } catch (error) {
    return {
      success: false,
      error: error instanceof Error ? error.message : String(error),
      path: filePath
    };
  }
}
function parseHclForValidation(filePath) {
  const fileResult = safeReadFile(filePath);
  if (!fileResult.success) {
    return fileResult;
  }
  try {
    const hclContent = fileResult.data;
    const parsed = { target: {} };
    const targetRegex = /target\s+"([^"]+)"\s*\{([^}]*)\}/g;
    let match;
    match = targetRegex.exec(hclContent);
    while (match !== null) {
      const targetName = match[1];
      const targetBody = match[2];
      const target = {};
      const dockerfileMatch = targetBody.match(/dockerfile\s*=\s*"([^"]+)"/);
      if (dockerfileMatch) {
        target.dockerfile = dockerfileMatch[1];
      }
      const contextMatch = targetBody.match(/context\s*=\s*"([^"]+)"/);
      if (contextMatch) {
        target.context = contextMatch[1];
      }
      const dependsOnMatch = targetBody.match(/depends_on\s*=\s*\[([^\]]*)\]/);
      if (dependsOnMatch) {
        const deps = dependsOnMatch[1].split(",").map((dep) => dep.trim().replace(/"/g, "")).filter((dep) => dep.length > 0);
        target.depends_on = deps;
      }
      const targetStartIndex = hclContent.indexOf(`target "${targetName}" {`);
      if (targetStartIndex !== -1) {
        let braceCount = 0;
        const startIndex = hclContent.indexOf("{", targetStartIndex) + 1;
        let endIndex = startIndex;
        for (let i = startIndex; i < hclContent.length; i++) {
          if (hclContent[i] === "{") braceCount++;
          else if (hclContent[i] === "}") {
            if (braceCount === 0) {
              endIndex = i;
              break;
            }
            braceCount--;
          }
        }
        const fullTargetBody = hclContent.substring(startIndex, endIndex);
        const contextsMatch = fullTargetBody.match(/contexts\s*=\s*\{([^}]*)\}/);
        if (contextsMatch) {
          const contextsBody = contextsMatch[1];
          const contexts = {};
          const kvRegex = /(\w+)\s*=\s*"([^"]*)"/g;
          let kvMatch;
          kvMatch = kvRegex.exec(contextsBody);
          while (kvMatch !== null) {
            contexts[kvMatch[1]] = kvMatch[2];
            kvMatch = kvRegex.exec(contextsBody);
          }
          if (Object.keys(contexts).length > 0) {
            target.contexts = contexts;
          }
        }
      }
      parsed.target[targetName] = target;
      match = targetRegex.exec(hclContent);
    }
    return {
      success: true,
      data: parsed
    };
  } catch (error) {
    return {
      success: false,
      error: `Failed to parse HCL: ${error instanceof Error ? error.message : String(error)}`,
      path: filePath
    };
  }
}
function validateBakeFileDependencies(config, projectDir) {
  const errors = [];
  const allBakeTargets = {};
  const contextDir = node_path.resolve(projectDir, config.project?.context || ".");
  for (const bakeFile of config.project?.bake || []) {
    const bakeFilePath = node_path.resolve(contextDir, bakeFile);
    if (!node_fs.existsSync(bakeFilePath)) {
      errors.push({
        type: "file",
        message: `Bake file not found: ${bakeFile}`
      });
      continue;
    }
    try {
      const hclResult = parseHclForValidation(bakeFilePath);
      if (!hclResult.success) {
        errors.push({
          type: "file",
          message: `Failed to read bake file ${bakeFile}: ${hclResult.error}`
        });
        continue;
      }
      const bakeConfig = hclResult.data;
      if (bakeConfig.target) {
        for (const [targetName, targetConfig] of Object.entries(bakeConfig.target)) {
          if (allBakeTargets[targetName]) {
            errors.push({
              type: "dependency",
              message: `Duplicate bake target '${targetName}' found in bake files.`
            });
          } else {
            allBakeTargets[targetName] = targetConfig;
          }
        }
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      errors.push({
        type: "file",
        message: `Failed to read or parse bake file ${bakeFile}: ${errorMessage}`
      });
    }
  }
  for (const targetName of Object.keys(config.targets)) {
    if (!allBakeTargets[targetName]) {
      errors.push({
        type: "dependency",
        target: targetName,
        message: `Target '${targetName}' not found in any of the specified bake files.`
      });
    }
  }
  try {
    buildDependencyTree(allBakeTargets);
  } catch (error) {
    if (error instanceof CyclicDependencyError) {
      errors.push({
        type: "dependency",
        message: `Cyclic dependency found in bake files: ${error.message}`
      });
    }
  }
  return errors;
}
function validateDependencies(config, _filePath) {
  const errors = [];
  const targetsUsingJq = Object.entries(config.targets || {}).filter(([, target]) => target.calculate_on?.jq);
  if (targetsUsingJq.length > 0) {
    try {
      node_child_process.execSync("which jq", { stdio: "ignore" });
    } catch {
      errors.push({
        type: "dependency",
        message: "jq command not found. Install jq to use jq-based calculate_on criteria."
      });
    }
  }
  return errors;
}
class ContextResolver {
  orckaDirPath;
  config;
  bakeConfigs = /* @__PURE__ */ new Map();
  constructor(dockerShaFilePath, config) {
    this.orckaDirPath = node_path.dirname(node_path.resolve(dockerShaFilePath));
    this.config = config;
  }
  /**
   * Sets parsed bake configurations for context resolution
   */
  setBakeConfigs(bakeConfigs) {
    this.bakeConfigs = bakeConfigs;
  }
  /**
   * Gets the orcka context (project context or docker-sha.yml location)
   */
  getOrckaContext() {
    return node_path.resolve(this.orckaDirPath, this.config.project?.context || ".");
  }
  /**
   * Resolves the context for a specific target based on context_of setting
   */
  resolveTargetContext(targetName, target) {
    const contextOf = target.context_of || "orcka";
    switch (contextOf) {
      case "orcka":
        return this.getOrckaContext();
      case "dockerfile":
        return this.resolveDockerfileContext(targetName);
      case "target":
        return this.resolveBakeTargetContext(targetName);
      case "bake":
        return this.resolveBakeFileContext(targetName);
      default:
        return this.getOrckaContext();
    }
  }
  /**
   * Resolves context to the directory containing the dockerfile for this target
   */
  resolveDockerfileContext(targetName) {
    const bakeTarget = this.findBakeTarget(targetName);
    if (bakeTarget?.dockerfile) {
      const dockerfilePath = node_path.resolve(this.getOrckaContext(), bakeTarget.dockerfile);
      return node_path.dirname(dockerfilePath);
    }
    return this.getOrckaContext();
  }
  /**
   * Resolves context to the bake target's context directory
   */
  resolveBakeTargetContext(targetName) {
    const bakeTarget = this.findBakeTarget(targetName);
    if (bakeTarget?.context) {
      return node_path.resolve(this.orckaDirPath, bakeTarget.context);
    }
    return this.getOrckaContext();
  }
  /**
   * Resolves context to the directory containing the bake file that defines this target
   */
  resolveBakeFileContext(targetName) {
    const bakeFilePath = this.findBakeFileForTarget(targetName);
    if (bakeFilePath) {
      return node_path.dirname(node_path.resolve(this.getOrckaContext(), bakeFilePath));
    }
    return this.getOrckaContext();
  }
  /**
   * Finds the bake target configuration for a given target name
   */
  findBakeTarget(targetName) {
    for (const bakeConfig of this.bakeConfigs.values()) {
      if (bakeConfig.target?.[targetName]) {
        return bakeConfig.target[targetName];
      }
    }
    return null;
  }
  /**
   * Finds the bake file path that contains the given target
   */
  findBakeFileForTarget(targetName) {
    for (const [bakeFilePath, bakeConfig] of this.bakeConfigs.entries()) {
      if (bakeConfig.target?.[targetName]) {
        return bakeFilePath;
      }
    }
    return null;
  }
  /**
   * Resolves a file path relative to the target's context
   */
  resolveFilePath(targetName, target, filePath) {
    const targetContext = this.resolveTargetContext(targetName, target);
    return node_path.resolve(targetContext, filePath);
  }
}
function validateFileExistence(config, filePath, bakeConfigs) {
  const errors = [];
  const contextResolver = new ContextResolver(filePath, config);
  if (bakeConfigs) {
    contextResolver.setBakeConfigs(bakeConfigs);
  }
  const orckaContext = contextResolver.getOrckaContext();
  if (config.project?.bake) {
    for (const bakeFile of config.project.bake) {
      const bakeFilePath = node_path.resolve(orckaContext, bakeFile);
      if (!node_fs.existsSync(bakeFilePath)) {
        errors.push({
          type: "file",
          message: `Bake file not found: ${bakeFile}`,
          path: bakeFilePath
        });
      }
    }
  }
  if (config.targets) {
    for (const [targetName, target] of Object.entries(config.targets)) {
      if (target.calculate_on?.files) {
        for (const file of target.calculate_on.files) {
          const fullPath = contextResolver.resolveFilePath(targetName, target, file);
          if (!node_fs.existsSync(fullPath)) {
            errors.push({
              type: "file",
              target: targetName,
              message: `File not found: ${file}`,
              path: fullPath
            });
          }
        }
      }
    }
  }
  return errors;
}
function validateSchema(config) {
  const errors = [];
  if (config.project) {
    if (!config.project.name) {
      errors.push({
        type: "schema",
        message: "project.name is required"
      });
    }
    if (!config.project.write) {
      errors.push({
        type: "schema",
        message: "project.write is required"
      });
    }
    if (!config.project.bake || !Array.isArray(config.project.bake) || config.project.bake.length === 0) {
      errors.push({
        type: "schema",
        message: "project.bake is required and must be a non-empty array"
      });
    }
  }
  if (config.targets) {
    for (const [targetName, target] of Object.entries(config.targets)) {
      if (!target.calculate_on) {
        continue;
      }
      const calculateOn = target.calculate_on;
      const hasValidCriteria = calculateOn.always === true || calculateOn.period || calculateOn.files && Array.isArray(calculateOn.files) && calculateOn.files.length > 0 || calculateOn.jq && typeof calculateOn.jq === "string";
      if (!hasValidCriteria) {
        errors.push({
          type: "schema",
          target: targetName,
          message: `Target '${targetName}' must have at least one valid calculate_on criteria (always, period, files, or jq)`
        });
      }
      if (calculateOn.period) {
        if (typeof calculateOn.period === "string") {
          const validStringPeriods = ["hourly", "weekly", "monthly", "yearly"];
          if (!validStringPeriods.includes(calculateOn.period)) {
            errors.push({
              type: "schema",
              target: targetName,
              message: `Target '${targetName}' has invalid period format. Valid string periods are: ${validStringPeriods.join(", ")}`
            });
          }
        } else if (typeof calculateOn.period === "object" && calculateOn.period !== null) {
          const period = calculateOn.period;
          if (!period.unit) {
            errors.push({
              type: "schema",
              target: targetName,
              message: `Target '${targetName}' period must have a unit field`
            });
          } else if (!["months", "weeks", "days", "hours", "minutes", "none"].includes(period.unit)) {
            errors.push({
              type: "schema",
              target: targetName,
              message: `Target '${targetName}' has invalid period unit '${period.unit}'. Valid units are: months, weeks, days, hours, minutes, none`
            });
          }
          if (period.unit !== "none" && (typeof period.number !== "number" || period.number <= 0)) {
            errors.push({
              type: "schema",
              target: targetName,
              message: `Target '${targetName}' period must have a positive number when unit is not 'none'`
            });
          }
        }
      }
      if (target.context_of) {
        const validContextOfValues = ["dockerfile", "orcka", "target", "bake"];
        if (!validContextOfValues.includes(target.context_of)) {
          errors.push({
            type: "schema",
            target: targetName,
            message: `Target '${targetName}' has invalid context_of value '${target.context_of}'. Valid values are: ${validContextOfValues.join(", ")}`
          });
        }
      }
    }
  }
  return errors;
}
function validateRequiredTopLevelFields(config, errors, filePath) {
  const configObj = config;
  if (!configObj.project) {
    errors.push({
      type: "schema",
      message: "Missing required 'project' section in docker-sha.yml",
      path: filePath
    });
  }
  if (!configObj.targets) {
    errors.push({
      type: "schema",
      message: "Missing required 'targets' section in docker-sha.yml",
      path: filePath
    });
  }
}
function generateWarnings(config) {
  const warnings = [];
  if (config.targets) {
    for (const [targetName, target] of Object.entries(config.targets)) {
      if (target.calculate_on?.always === true) {
        const hasOtherCriteria = target.calculate_on.files || target.calculate_on.period || target.calculate_on.jq;
        if (!hasOtherCriteria) {
          warnings.push({
            type: "performance",
            target: targetName,
            message: `Target '${targetName}' uses 'always: true' without other criteria. Consider using period, files, or jq for better performance.`
          });
        }
      }
      if (target.calculate_on?.period) {
        if (typeof target.calculate_on.period === "object" && "unit" in target.calculate_on.period) {
          const period = target.calculate_on.period;
          if (period.unit === "minutes" || period.unit === "hours" && period.number === 1) {
            warnings.push({
              type: "performance",
              target: targetName,
              message: `Target '${targetName}' has a very short period (${period.number} ${period.unit}). This may cause frequent rebuilds.`
            });
          }
        } else if (typeof target.calculate_on.period === "string" && target.calculate_on.period === "hourly") {
          warnings.push({
            type: "performance",
            target: targetName,
            message: `Target '${targetName}' uses hourly period. This may cause frequent rebuilds.`
          });
        }
      }
    }
  }
  return warnings;
}
async function parseBakeConfigs(config, filePath) {
  const projectDir = node_path.dirname(node_path.resolve(filePath));
  const contextDir = node_path.resolve(projectDir, config.project?.context || ".");
  if (!config.project?.bake) {
    return /* @__PURE__ */ new Map();
  }
  const parseResults = await HclParser.parseHclFilesFromContext(contextDir, config.project.bake, {
    useFallback: true,
    silent: true
  });
  return extractBakeConfigs(parseResults);
}
async function validateDockerShaFile(filePath) {
  const errors = [];
  const warnings = [];
  try {
    if (!node_fs.existsSync(filePath)) {
      errors.push({
        type: "file",
        message: `docker-sha.yml file not found: ${filePath}`,
        path: filePath
      });
      return { valid: false, errors, warnings };
    }
    const fileContent = node_fs.readFileSync(filePath, "utf-8");
    const config = yaml.parse(fileContent);
    const bakeConfigs = await parseBakeConfigs(config, filePath);
    validateRequiredTopLevelFields(config, errors, filePath);
    if (config.project) {
      const projectErrors = validateSchema(config);
      errors.push(...projectErrors);
    }
    const fileErrors = validateFileExistence(config, filePath, bakeConfigs);
    errors.push(...fileErrors);
    const depErrors = validateDependencies(config, filePath);
    errors.push(...depErrors);
    const needsBakeValidation = Object.keys(config.targets || {}).length > 0 && config.project?.bake;
    if (needsBakeValidation) {
      const bakeErrors = validateBakeFileDependencies(config, node_path.dirname(node_path.resolve(filePath)));
      const relevantErrors = bakeErrors.filter(
        (error) => error.message.includes("not found in any of the specified bake files") || error.message.includes("Cyclic dependency found")
      );
      errors.push(...relevantErrors);
    }
    const warningList = generateWarnings(config);
    warnings.push(...warningList);
    return {
      valid: errors.length === 0,
      errors,
      warnings,
      config: errors.length === 0 ? config : void 0
    };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    errors.push({
      type: "file",
      message: `Unexpected error during validation: ${errorMessage}`,
      path: filePath
    });
    return { valid: false, errors, warnings };
  }
}
function validateTargetsAndVariables(config, allBakeTargets, bakeConfigs) {
  const errors = [];
  for (const [targetName] of Object.entries(config.targets)) {
    if (!allBakeTargets[targetName]) {
      errors.push(`Target '${targetName}' not found in any bake file`);
      continue;
    }
    const hclVarName = generateHclVariableName$1(targetName);
    const expectedVarName = `${hclVarName}_TAG_VER`;
    if (!isVariableDeclaredInBakeConfigs(expectedVarName, bakeConfigs)) {
      errors.push(
        `Variable '${expectedVarName}' not found in any bake file. Please declare: variable "${expectedVarName}" { default = "" }`
      );
    }
  }
  return errors;
}
function generateHclVariableName$1(targetName) {
  return targetName.replace(/-/g, "_").toUpperCase();
}
function isVariableDeclaredInBakeConfigs(variableName, bakeConfigs) {
  for (const bakeConfig of bakeConfigs.values()) {
    if (bakeConfig.variable && variableName in bakeConfig.variable) {
      return true;
    }
  }
  return false;
}
const DEFAULT_DOT_CONFIG = {
  rankDirection: "LR",
  nodeShape: "box",
  nodeStyle: "rounded,filled",
  alwaysColor: "lightcoral",
  defaultColor: "lightblue"
};
function generateDotFile(config, dependencyTree, outPath, dotConfig = DEFAULT_DOT_CONFIG) {
  const lines = [];
  lines.push("digraph ServiceDependencies {");
  lines.push(`  rankdir=${dotConfig.rankDirection};`);
  lines.push(`  node [shape=${dotConfig.nodeShape}, style="${dotConfig.nodeStyle}"];`);
  lines.push("");
  for (const [serviceName, shaTarget] of Object.entries(config.targets)) {
    const nodeDefinition = generateNodeDefinition(serviceName, shaTarget.calculate_on, dotConfig);
    lines.push(nodeDefinition);
  }
  lines.push("");
  const edges = generateDependencyEdges(dependencyTree);
  lines.push(...edges);
  lines.push("}");
  node_fs.writeFileSync(outPath, lines.join("\n"), "utf8");
}
function generateNodeDefinition(serviceName, calculateOn, config = DEFAULT_DOT_CONFIG) {
  const criteria = extractRebuildCriteria(calculateOn);
  const criteriaText = criteria.length > 0 ? `\\n(${criteria.join(", ")})` : "";
  const nodeColor = calculateOn?.always ? config.alwaysColor : config.defaultColor;
  return `  "${serviceName}" [label="${serviceName}${criteriaText}", fillcolor=${nodeColor}];`;
}
function extractRebuildCriteria(calculateOn) {
  if (!calculateOn) return [];
  const criteria = [];
  if (calculateOn.always) {
    criteria.push("always");
  }
  if (calculateOn.period) {
    criteria.push(formatPeriodCriteria(calculateOn.period));
  }
  if (calculateOn.files?.length) {
    criteria.push(`${calculateOn.files.length} files`);
  }
  if (calculateOn.jq) {
    criteria.push("jq");
  }
  return criteria;
}
function formatPeriodCriteria(period) {
  if (typeof period === "string") {
    return period;
  }
  if (typeof period === "object" && "number" in period) {
    return `${period.number} ${period.unit}`;
  }
  if (typeof period === "object" && period.unit === "none") {
    return "none";
  }
  return "unknown";
}
function generateDependencyEdges(dependencyTree) {
  const edges = [];
  for (const [serviceName, node] of dependencyTree.nodes) {
    for (const dependency of node.dependencies) {
      edges.push(`  "${dependency}" -> "${serviceName}";`);
    }
  }
  return edges;
}
function buildDependencyMap(dependencyTree) {
  const dependencyMap = {};
  for (const [serviceName, node] of dependencyTree.nodes) {
    dependencyMap[serviceName] = node.dependencies;
  }
  return dependencyMap;
}
function formatTimestamp(date, period) {
  const year = date.getUTCFullYear().toString();
  const month = (date.getUTCMonth() + 1).toString().padStart(2, "0");
  const day = date.getUTCDate().toString().padStart(2, "0");
  const hour = date.getUTCHours().toString().padStart(2, "0");
  const minute = date.getUTCMinutes().toString().padStart(2, "0");
  const second = date.getUTCSeconds().toString().padStart(2, "0");
  if (typeof period === "string") {
    return formatStringPeriod(period, year, month, day, hour);
  }
  if (period && typeof period === "object" && "unit" in period) {
    return formatObjectPeriod(period, year, month, day, hour, minute, second);
  }
  return `${year}${month}${day}_${hour}${minute}${second}`;
}
function formatStringPeriod(period, year, month, day, hour, _minute, _second) {
  switch (period) {
    case "hourly":
      return `${year}${month}${day}_${hour}`;
    // year, month, day, hour
    case "weekly":
      return `${year}${month}${day}`;
    // year, month, day (weekly granularity)
    case "monthly":
      return `${year}${month}`;
    // year, month
    case "yearly":
      return `${year}`;
    // year only
    default:
      throw new Error(`Unknown string period format: ${period}`);
  }
}
function formatObjectPeriod(period, year, month, day, hour, minute, second) {
  if (period.unit === "none") {
    return "";
  }
  switch (period.unit) {
    case "seconds":
      return `${year}${month}${day}_${hour}${minute}${second}`;
    // All values (most granular)
    case "minutes":
      return `${year}${month}${day}_${hour}${minute}`;
    // down to minutes
    case "hours":
      return `${year}${month}${day}_${hour}`;
    // down to hours
    case "days":
      return `${year}${month}${day}`;
    // down to days
    case "weeks":
      return `${year}${month}${day}`;
    // down to days (weekly granularity)
    case "months":
      return `${year}${month}`;
    // down to months
    default:
      throw new Error(`Unknown object period unit: ${period.unit}`);
  }
}
async function generateServiceTags({
  config,
  bakeTargets,
  servicesInOrder,
  projectDir,
  logger,
  composeTagMap,
  buildHashInput: buildHashInput2,
  currentTime = /* @__PURE__ */ new Date()
}) {
  const resolvedTags = /* @__PURE__ */ new Map();
  const services = [];
  for (const serviceName of servicesInOrder) {
    const result = await processService({
      serviceName,
      config,
      bakeTargets,
      resolvedTags,
      currentTime,
      projectDir,
      logger,
      composeTagMap,
      // Pass compose tag map
      buildHashInput: buildHashInput2
    });
    if (result) {
      services.push(result);
    }
  }
  return { services, resolvedTags };
}
async function processService({
  serviceName,
  config,
  bakeTargets,
  resolvedTags,
  currentTime,
  projectDir,
  logger,
  composeTagMap,
  buildHashInput: buildHashInput2
}) {
  const bakeTarget = bakeTargets[serviceName];
  if (!bakeTarget) return null;
  if (typeof bakeTarget !== "object" || bakeTarget === null) {
    logger.verbose(`Skipping non-target entry: ${serviceName}`);
    return null;
  }
  const shaTarget = config.targets[serviceName];
  if (shaTarget?.skip_calculate === true) {
    logger.verbose(`Skipping calculation for ${serviceName} (skip_calculate: true)`);
    return null;
  }
  logger.logServiceProcessing(serviceName, "Processing service");
  const hashInput = await buildHashInput2(
    bakeTarget,
    shaTarget?.calculate_on,
    resolvedTags,
    projectDir,
    logger,
    serviceName
  );
  const hash = node_crypto.createHash("sha1").update(hashInput).digest("hex");
  const tagVersion = generateTagVersion(currentTime, shaTarget?.calculate_on?.period, hash);
  const baseTag = bakeTarget.tags?.[0] ?? serviceName;
  const imageName = baseTag.split(":")[0];
  const fullImageTag = `${imageName}:${tagVersion}`;
  resolvedTags.set(serviceName, fullImageTag);
  const varName = generateHclVariableName(serviceName);
  const targetType = shaTarget?.calculate_on ? "configured" : "default";
  logger.logServiceProcessing(serviceName, `Generated (${targetType})`, `${varName} = "${tagVersion}"`);
  const composeTag = composeTagMap?.get(serviceName);
  const composeReference = composeTag ? `${imageName}:${composeTag}` : void 0;
  return {
    name: serviceName,
    varName,
    imageTag: tagVersion,
    imageReference: fullImageTag,
    composeTag,
    composeReference
  };
}
function generateTagVersion(currentTime, period, hash) {
  const timestamp = period ? formatTimestamp(currentTime, period) : "";
  if (timestamp === "") {
    return hash;
  }
  const prefixLength = timestamp.length + 1;
  const truncatedHash = hash.slice(prefixLength);
  return `${timestamp}_${truncatedHash}`;
}
function generateHclVariableName(serviceName) {
  return serviceName.replace(/[^a-zA-Z0-9]+/g, "_").replace(/_+/g, "_").replace(/^_|_$/g, "").toUpperCase().concat("_TAG_VER");
}
function resolveComposeTags(composeFiles, options = {}) {
  const result = {
    tags: [],
    warnings: []
  };
  if (composeFiles.length === 0) {
    return result;
  }
  try {
    const configs = composeFiles.map((file) => parseComposeFile(file, result.warnings));
    const mergedConfig = options.applyMerging ? mergeComposeConfigs(configs) : configs[0];
    if (!mergedConfig?.services) {
      result.warnings.push("No services found in compose files");
      return result;
    }
    const processEnvFiltered = {};
    for (const [key, value] of Object.entries(process.env)) {
      if (value !== void 0) {
        processEnvFiltered[key] = value;
      }
    }
    const env = { ...processEnvFiltered, ...options.env || {} };
    for (const [serviceName, service] of Object.entries(mergedConfig.services)) {
      if (!service.image) {
        continue;
      }
      const imageTag = extractImageTag(serviceName, service.image, env);
      if (imageTag) {
        result.tags.push(imageTag);
      } else {
        result.warnings.push(`Could not parse image for service: ${serviceName}`);
      }
    }
    return result;
  } catch (error) {
    result.warnings.push(`Error resolving compose tags: ${error instanceof Error ? error.message : String(error)}`);
    return result;
  }
}
function parseComposeFile(filePath, warnings) {
  try {
    const content = node_fs.readFileSync(filePath, "utf-8");
    return yaml.parse(content);
  } catch (error) {
    warnings.push(`Failed to parse ${filePath}: ${error instanceof Error ? error.message : String(error)}`);
    return null;
  }
}
function mergeComposeConfigs(configs) {
  const merged = { services: {} };
  for (const config of configs) {
    if (!config) continue;
    if (config.services) {
      merged.services = {
        ...merged.services,
        ...config.services
      };
    }
  }
  return merged;
}
function extractImageTag(serviceName, imageString, env) {
  const hasVariables = imageString.includes("${") || imageString.includes("$");
  const originalLastColon = findTagColonIndex(imageString);
  const originalTag = originalLastColon === -1 ? "latest" : imageString.substring(originalLastColon + 1);
  const resolvedImage = resolveEnvVars(imageString, env);
  const lastColonIndex = findTagColonIndex(resolvedImage);
  let imageName;
  let tag;
  if (lastColonIndex === -1) {
    imageName = resolvedImage;
    tag = "latest";
  } else {
    imageName = resolvedImage.substring(0, lastColonIndex);
    tag = resolvedImage.substring(lastColonIndex + 1);
  }
  return {
    serviceName,
    imageName,
    tag,
    originalTag,
    hasVariables
  };
}
function findTagColonIndex(imageString) {
  const lastColonIndex = imageString.lastIndexOf(":");
  if (lastColonIndex === -1) {
    return -1;
  }
  const afterColon = imageString.substring(lastColonIndex + 1);
  if (afterColon.includes("/")) {
    const beforeColon = imageString.substring(0, lastColonIndex);
    return findTagColonIndex(beforeColon);
  }
  return lastColonIndex;
}
function resolveEnvVars(str, env) {
  return str.replace(/\$\{([^}:-]+)(:?-([^}]+))?\}/g, (match, varName, _, defaultValue) => {
    const envValue = env[varName];
    if (envValue !== void 0 && envValue !== "") {
      return envValue;
    }
    if (defaultValue !== void 0) {
      return defaultValue;
    }
    return match;
  });
}
function matchServicesToTargets(composeTags, bakeTargets) {
  const matches = /* @__PURE__ */ new Map();
  for (const composeTag of composeTags) {
    if (bakeTargets[composeTag.serviceName]) {
      matches.set(composeTag.serviceName, composeTag.serviceName);
      continue;
    }
    const normalized = composeTag.serviceName.replace(/-/g, "_");
    if (bakeTargets[normalized]) {
      matches.set(composeTag.serviceName, normalized);
      continue;
    }
    for (const [targetName, target] of Object.entries(bakeTargets)) {
      if (typeof target === "object" && target !== null && "tags" in target) {
        const tags = target.tags || [];
        for (const tag of tags) {
          const bakeImageName = tag.split(":")[0];
          if (bakeImageName === composeTag.imageName) {
            matches.set(composeTag.serviceName, targetName);
            break;
          }
        }
      }
    }
  }
  return matches;
}
const DEFAULT_HCL_CONFIG = {
  includePullPolicy: true,
  defaultPullPolicy: "never",
  alignVariables: true
};
async function generateCalculatedHcl(config, bakeTargets, servicesInOrder, projectDir, logger, buildHashInputFn, hclConfig = DEFAULT_HCL_CONFIG, composeFiles) {
  let composeTagMap;
  if (composeFiles && composeFiles.length > 0) {
    logger.verbose("Resolving compose file image tags...");
    const composeResult = resolveComposeTags(composeFiles, { applyMerging: true });
    if (composeResult.warnings.length > 0) {
      for (const warning of composeResult.warnings) {
        logger.verbose(`Compose tag warning: ${warning}`);
      }
    }
    const serviceMatches = matchServicesToTargets(composeResult.tags, bakeTargets);
    composeTagMap = /* @__PURE__ */ new Map();
    for (const composeTag of composeResult.tags) {
      const targetName = serviceMatches.get(composeTag.serviceName);
      if (targetName) {
        composeTagMap.set(targetName, composeTag.tag);
        logger.verbose(`Matched compose service '${composeTag.serviceName}' → target '${targetName}' with tag '${composeTag.tag}'`);
      }
    }
  }
  const { services: generatedServices, resolvedTags } = await generateServiceTags({
    config,
    bakeTargets,
    servicesInOrder,
    projectDir,
    logger,
    composeTagMap,
    buildHashInput: buildHashInputFn
  });
  const hclOutput = formatHclOutput(generatedServices, hclConfig);
  return { hclOutput, generatedServices, resolvedTags };
}
function generatePullPolicyVariableName(tagVarName) {
  return tagVarName.replace("_TAG_VER", "_PULL_POLICY");
}
function formatHclOutput(generatedServices, config = DEFAULT_HCL_CONFIG) {
  const allVariables = [];
  for (const service of generatedServices) {
    allVariables.push({
      name: service.varName,
      value: service.imageTag
    });
  }
  if (config.includePullPolicy) {
    for (const service of generatedServices) {
      const pullPolicyVarName = generatePullPolicyVariableName(service.varName);
      allVariables.push({
        name: pullPolicyVarName,
        value: config.defaultPullPolicy || "never"
      });
    }
  }
  if (config.alignVariables) {
    return formatAlignedVariables(allVariables);
  } else {
    return formatSimpleVariables(allVariables);
  }
}
function formatAlignedVariables(variables) {
  const maxVarNameLength = Math.max(...variables.map((variable) => variable.name.length));
  const alignedHclLines = variables.map((variable) => {
    const padding = " ".repeat(maxVarNameLength - variable.name.length);
    return `${variable.name}${padding} = "${variable.value}"`;
  });
  return alignedHclLines.join("\n");
}
function formatSimpleVariables(variables) {
  return variables.map((variable) => `${variable.name} = "${variable.value}"`).join("\n");
}
class AsciiTreeGenerator {
  options;
  constructor(options = {}) {
    this.options = {
      showRebuildCriteria: true,
      detectPatterns: true,
      maxDepth: 10,
      ...options
    };
  }
  /**
   * Generate ASCII tree from bake targets and dependency information
   */
  generateTree(bakeTargets, dependencyMap, configFile, bakeFiles) {
    const nodes = this.buildNodes(bakeTargets, dependencyMap);
    const { rootNodes, patternNodes } = this.analyzeNodes(nodes);
    const output = [];
    output.push("🌳 Docker Build Target Hierarchy");
    output.push(`📁 Config file: ${configFile}`);
    output.push(`📁 Bake files: ${bakeFiles.join(", ")}`);
    output.push("");
    if (patternNodes.length > 0 && this.options.detectPatterns) {
      output.push("🔄 Pattern Targets (Reusable Components):");
      output.push("");
      for (let i = 0; i < patternNodes.length; i++) {
        const isLast = i === patternNodes.length - 1;
        const pattern = patternNodes[i];
        output.push(`${isLast ? "└── " : "├── "}${pattern.name}${this.formatRebuildCriteria(pattern)}`);
        this.renderSubtree(pattern, nodes, output, isLast ? "    " : "│   ", /* @__PURE__ */ new Set(), 0);
      }
      output.push("");
    }
    if (rootNodes.length > 0) {
      output.push("🎯 Root Targets:");
      output.push("");
      for (let i = 0; i < rootNodes.length; i++) {
        const isLast = i === rootNodes.length - 1;
        const root = rootNodes[i];
        output.push(`${isLast ? "└── " : "├── "}${root.name}${this.formatRebuildCriteria(root)}`);
        this.renderSubtree(root, nodes, output, isLast ? "    " : "│   ", /* @__PURE__ */ new Set([root.name]), 0);
      }
    } else {
      output.push("⚠️  No clear root targets found");
    }
    output.push("");
    output.push("📊 Summary:");
    output.push(`Total targets: ${Object.keys(nodes).length}`);
    output.push(`Root targets: ${rootNodes.length}`);
    output.push(`Pattern targets: ${patternNodes.length}`);
    output.push(`Targets with dependencies: ${Object.values(nodes).filter((n) => n.dependencies.length > 0).length}`);
    return output.join("\n");
  }
  /**
   * Build tree nodes from bake targets and dependencies
   */
  buildNodes(bakeTargets, dependencyMap) {
    const nodes = {};
    for (const [name, target] of Object.entries(bakeTargets)) {
      const dependencies = dependencyMap[name] || [];
      const rebuildCriteria = this.extractRebuildCriteria(target);
      nodes[name] = {
        name,
        dependencies,
        rebuildCriteria,
        isPattern: false
        // Will be determined in analyzeNodes
      };
    }
    return nodes;
  }
  /**
   * Analyze nodes to identify root targets and patterns
   */
  analyzeNodes(nodes) {
    const allTargets = Object.keys(nodes);
    const dependedUpon = /* @__PURE__ */ new Set();
    for (const node of Object.values(nodes)) {
      for (const dep of node.dependencies) {
        dependedUpon.add(dep);
      }
    }
    const rootTargets = allTargets.filter((name) => !dependedUpon.has(name));
    const patternTargets = allTargets.filter((name) => dependedUpon.has(name) && nodes[name].dependencies.length > 0);
    for (const patternName of patternTargets) {
      nodes[patternName].isPattern = true;
    }
    return {
      rootNodes: rootTargets.map((name) => nodes[name]).sort((a, b) => a.name.localeCompare(b.name)),
      patternNodes: patternTargets.map((name) => nodes[name]).sort((a, b) => a.name.localeCompare(b.name))
    };
  }
  /**
   * Recursively render subtree
   */
  renderSubtree(node, allNodes, output, prefix, visited, depth) {
    if (depth >= this.options.maxDepth) {
      output.push(`${prefix}└── ... (max depth reached)`);
      return;
    }
    const sortedDeps = [...node.dependencies].sort();
    for (let i = 0; i < sortedDeps.length; i++) {
      const depName = sortedDeps[i];
      const isLast = i === sortedDeps.length - 1;
      const depNode = allNodes[depName];
      if (!depNode) {
        output.push(`${prefix}${isLast ? "└── " : "├── "}${depName} (external)`);
        continue;
      }
      if (visited.has(depName)) {
        output.push(`${prefix}${isLast ? "└── " : "├── "}${depName} (↻)`);
        continue;
      }
      if (depNode.isPattern && this.options.detectPatterns) {
        output.push(
          `${prefix}${isLast ? "└── " : "├── "}${depName}${this.formatRebuildCriteria(depNode)} → see pattern above`
        );
        continue;
      }
      output.push(`${prefix}${isLast ? "└── " : "├── "}${depName}${this.formatRebuildCriteria(depNode)}`);
      if (depNode.dependencies.length > 0) {
        const newVisited = /* @__PURE__ */ new Set([...visited, depName]);
        const newPrefix = prefix + (isLast ? "    " : "│   ");
        this.renderSubtree(depNode, allNodes, output, newPrefix, newVisited, depth + 1);
      }
    }
  }
  /**
   * Extract rebuild criteria from bake target
   */
  extractRebuildCriteria(target) {
    if (target.contexts && Object.keys(target.contexts).length > 0) {
      return "context-dependent";
    }
    return "default";
  }
  /**
   * Format rebuild criteria for display
   */
  formatRebuildCriteria(node) {
    if (!this.options.showRebuildCriteria) {
      return "";
    }
    return ` [${node.rebuildCriteria}]`;
  }
}
const SECTION_ORDER = [
  { key: "orcka", label: "orcka" },
  { key: "bake", label: "bake" },
  { key: "compose", label: "compose" }
];
function formatMissingIndicator(key, value, missingEntries) {
  if (!missingEntries) {
    return "";
  }
  const missingSet = missingEntries[key];
  if (missingSet?.has(value)) {
    return " ❌";
  }
  return "";
}
function displayFilesSection(files, options = {}) {
  const header = options.header ?? "Reading files";
  const emoji = options.emoji ?? "✅";
  console.log("");
  console.log(`${emoji} ${header}:`);
  for (const { key, label } of SECTION_ORDER) {
    const entries = files[key];
    if (entries.length === 0) {
      continue;
    }
    if (entries.length === 1) {
      const entry = entries[0];
      const missingIndicator = formatMissingIndicator(key, entry, options.missingEntries);
      console.log(Clout.bullet(`${label}: ${entry}${missingIndicator}`));
    } else {
      console.log(Clout.bullet(`${label}:`));
      for (const entry of entries) {
        const missingIndicator = formatMissingIndicator(key, entry, options.missingEntries);
        console.log(Clout.dash(`${entry}${missingIndicator}`));
      }
    }
  }
}
function collectCalculationFiles(mainConfigFile, bakeFiles, composeFiles = []) {
  return {
    orcka: [mainConfigFile],
    bake: bakeFiles,
    compose: composeFiles
  };
}
function formatCalculationCriteria(calculateOn) {
  const flags = [];
  if (!calculateOn) {
    return "A";
  }
  const addFlag = (flag) => {
    if (!flags.includes(flag)) {
      flags.push(flag);
    }
  };
  if (calculateOn.files && calculateOn.files.length > 0) {
    addFlag("F");
  }
  if (calculateOn.jq) {
    addFlag("J");
  }
  if (calculateOn.period) {
    if (typeof calculateOn.period === "string") {
      addFlag(calculateOn.period.charAt(0).toUpperCase());
    } else if (calculateOn.period.unit === "none") {
      addFlag("N");
    } else if (calculateOn.period.unit) {
      addFlag(calculateOn.period.unit.charAt(0).toUpperCase());
    } else {
      addFlag("P");
    }
  }
  if (calculateOn.always) {
    addFlag("A");
  }
  if (calculateOn.date) {
    addFlag("D");
  }
  return flags.length > 0 ? flags.join("") : "A";
}
function displayTargetsSection(targets) {
  if (targets.length === 0) return;
  const hasComposeTags = targets.some((t) => t.composeTag && t.status === "success");
  const headers = hasComposeTags ? ["Target", "Calc", "Orcka Tag", "Compose Tag"] : ["Target", "Calc", "Tag"];
  const rows = targets.map((target) => {
    let tagVer = target.tagVer;
    if (target.status === "not_found") {
      tagVer = "❌ not found";
    } else if (target.status === "requires_dependency") {
      tagVer = `requires ${target.requiredTarget || "dependency"}`;
    }
    if (hasComposeTags) {
      const composeTag = target.composeTag || "-";
      return [target.name, target.calculationCriteria, tagVer, composeTag];
    } else {
      return [target.name, target.calculationCriteria, tagVer];
    }
  });
  const table2 = hasComposeTags ? Clout.table(headers, rows, {
    columnWidths: [16, 6, 24, 24],
    align: ["left", "left", "left", "left"],
    border: false,
    truncate: true
  }) : Clout.table(headers, rows, {
    columnWidths: [20, 8, 42],
    align: ["left", "left", "left"],
    border: false,
    truncate: true
  });
  console.log(table2);
}
async function buildHashInput(bakeTarget, calculateOn, resolvedTags, projectDir, logger, serviceName) {
  const hashParts = [];
  if (bakeTarget.dockerfile) {
    try {
      const dockerfilePath = node_path.join(bakeTarget.context ?? ".", bakeTarget.dockerfile);
      const dockerfileContent = node_fs.readFileSync(node_path.join(projectDir, dockerfilePath), "utf-8");
      hashParts.push(`dockerfile:${dockerfileContent}`);
      logger.logServiceProcessing(serviceName, "Added dockerfile content to hash");
    } catch {
      hashParts.push(`dockerfile-path:${bakeTarget.dockerfile}`);
      logger.logServiceProcessing(serviceName, "Added dockerfile path to hash (content not readable)");
    }
  }
  if (bakeTarget.args) {
    const sortedArgs = Object.keys(bakeTarget.args).sort();
    for (const key of sortedArgs) {
      hashParts.push(`arg:${key}=${bakeTarget.args[key]}`);
    }
  }
  if (bakeTarget.depends_on) {
    const sortedDeps = [...bakeTarget.depends_on].sort();
    for (const dep of sortedDeps) {
      const resolvedTag = resolvedTags.get(dep);
      if (resolvedTag) {
        hashParts.push(`dep:${dep}=${resolvedTag}`);
      }
    }
  }
  if (bakeTarget.contexts && typeof bakeTarget.contexts === "object") {
    const sortedContexts = Object.keys(bakeTarget.contexts).sort();
    for (const contextKey of sortedContexts) {
      const contextValue = bakeTarget.contexts[contextKey];
      const resolvedContextTag = resolvedTags.get(contextValue);
      if (resolvedContextTag) {
        hashParts.push(`context:${contextKey}=${resolvedContextTag}`);
        logger.logServiceProcessing(serviceName, `Added context dependency: ${contextKey}=${resolvedContextTag}`);
      } else {
        hashParts.push(`context:${contextKey}=${contextValue}`);
      }
    }
  }
  if (calculateOn) {
    if (calculateOn.files) {
      for (const filePath of calculateOn.files) {
        try {
          const fileContent = node_fs.readFileSync(node_path.join(projectDir, filePath), "utf-8");
          hashParts.push(`file:${filePath}:${fileContent}`);
        } catch {
          hashParts.push(`file-path:${filePath}`);
        }
      }
    }
    if (calculateOn.jq) {
      try {
        const jqFileContent = node_fs.readFileSync(node_path.join(projectDir, calculateOn.jq.filename), "utf-8");
        hashParts.push(`jq:${calculateOn.jq.filename}:${calculateOn.jq.selector}:${jqFileContent}`);
      } catch {
        hashParts.push(`jq-path:${calculateOn.jq.filename}:${calculateOn.jq.selector}`);
      }
    }
    if (calculateOn.period) {
      if (typeof calculateOn.period === "string") {
        hashParts.push(`period:${calculateOn.period}`);
      } else if (typeof calculateOn.period === "object" && "unit" in calculateOn.period) {
        const periodNumber = "number" in calculateOn.period ? calculateOn.period.number : "";
        hashParts.push(`period:${calculateOn.period.unit}:${periodNumber}`);
      }
    }
    if (calculateOn.always) {
      hashParts.push("always:true");
    }
  }
  return hashParts.join("\n");
}
async function calculateDockerSha(options) {
  const logger = new Logger({
    verbose: options.verbose ?? false,
    quiet: options.quiet ?? false
  });
  const projectDir = node_path.dirname(options.inputFile);
  let config = null;
  let outputFile = "";
  let contextDir = projectDir;
  let composeFiles = [];
  const allBakeTargets = {};
  let projectConfig = null;
  const shouldWriteOutput = options.writeOutput ?? true;
  const serviceFilterSet = (() => {
    const input = options.serviceFilter;
    if (!input) {
      return void 0;
    }
    if (input instanceof Set) {
      return new Set(input);
    }
    if (Array.isArray(input)) {
      return new Set(input);
    }
    return void 0;
  })();
  logger.verbose(`Starting docker-sha calculation for: ${options.inputFile}`);
  try {
    logger.verbose("Parsing docker-sha.yml configuration...");
    const shaFileContent = node_fs.readFileSync(options.inputFile, "utf-8");
    config = yaml.parse(shaFileContent);
    if (!config) {
      throw new Error("Unable to parse docker-sha configuration");
    }
    const parsedProject = config.project;
    projectConfig = parsedProject ?? {
      name: "orcka",
      bake: []
    };
    contextDir = node_path.join(projectDir, projectConfig.context || ".");
    composeFiles = Array.isArray(projectConfig.compose) ? projectConfig.compose : [];
    const outputDir = ensureOrckaDirectory(contextDir);
    outputFile = resolveTagsOutputPath(contextDir, projectConfig);
    logger.verbose(`Context directory: ${contextDir}`);
    logger.verbose(`Output directory: ${outputDir}`);
    logger.verbose(`Output file: ${outputFile}`);
    if (!options.quiet && projectConfig.bake && Array.isArray(projectConfig.bake)) {
      const filesData = collectCalculationFiles(options.inputFile, projectConfig.bake, composeFiles);
      const missingEntries = {};
      const ensureMissingSet = (key) => {
        if (!missingEntries[key]) {
          missingEntries[key] = /* @__PURE__ */ new Set();
        }
        return missingEntries[key] ?? /* @__PURE__ */ new Set();
      };
      let hasMissingFiles = false;
      for (const bakeFile of filesData.bake) {
        const bakeFilePath = node_path.join(contextDir, bakeFile);
        if (!node_fs.existsSync(bakeFilePath)) {
          hasMissingFiles = true;
          ensureMissingSet("bake").add(bakeFile);
        }
      }
      for (const composeFile of filesData.compose) {
        const composeFilePath = node_path.join(contextDir, composeFile);
        if (!node_fs.existsSync(composeFilePath)) {
          hasMissingFiles = true;
          ensureMissingSet("compose").add(composeFile);
        }
      }
      displayFilesSection(filesData, {
        emoji: hasMissingFiles ? "🔴" : "✅",
        missingEntries: Object.keys(missingEntries).length > 0 ? missingEntries : void 0
      });
    }
    logger.verbose("Validating docker-sha.yml configuration...");
    const validationResult = await validateDockerShaFile(options.inputFile);
    if (!validationResult.valid) {
      if (!options.quiet) {
        const configTargets = Object.keys(config.targets || {});
        if (configTargets.length > 0) {
          console.log("");
          console.log("🔴 Calculating targets:");
          for (const targetName of configTargets) {
            console.log(`  • ${targetName}`);
          }
        }
        console.log("");
        console.log("❌ Errors:");
        for (const error of validationResult.errors) {
          console.log(`❌ ${error.message}`);
        }
      }
      return {
        success: false,
        outputFile,
        projectContext: contextDir,
        project: projectConfig,
        servicesCalculated: 0,
        generatedServices: [],
        resolvedTags: {},
        composeFiles,
        bakeTargets: allBakeTargets,
        errors: validationResult.errors.map((e) => e.message)
      };
    }
    logger.verbose("✓ Configuration validation passed");
    const bakeFiles = projectConfig.bake || [];
    logger.verbose(`Processing ${bakeFiles.length} bake file(s)...`);
    const bakeFileContents = /* @__PURE__ */ new Map();
    const parsedBakeConfigs = /* @__PURE__ */ new Map();
    for (const bakeFile of bakeFiles) {
      const bakeFilePath = node_path.join(contextDir, bakeFile);
      logger.verbose(`Reading bake file: ${bakeFile}`);
      try {
        const bakeFileContent = node_fs.readFileSync(bakeFilePath, "utf-8");
        bakeFileContents.set(bakeFilePath, bakeFileContent);
        const parseResult = await HclParser.parseHclFile(bakeFilePath, bakeFile, {
          useFallback: false,
          silent: false
        });
        if (!parseResult.success) {
          logger.error(`HCL parsing failed for ${bakeFile}: ${parseResult.error}`);
        }
        const bakeConfig = parseResult.success && parseResult.data ? parseResult.data : { target: {} };
        parsedBakeConfigs.set(bakeFile, bakeConfig);
        if (bakeConfig?.target) {
          const targetCount = Object.keys(bakeConfig.target).length;
          logger.verbose(`Found ${targetCount} target(s) in ${bakeFile}`);
          for (const [targetName, targetConfig] of Object.entries(bakeConfig.target)) {
            if (targetName.includes(")") || targetName.includes("(")) {
              logger.verbose(`Skipping invalid target name with parentheses: ${targetName}`);
              continue;
            }
            if (targetConfig && typeof targetConfig === "object") {
              allBakeTargets[targetName] = targetConfig;
            } else {
              logger.verbose(`Skipping invalid target: ${targetName}`);
            }
          }
        }
      } catch (e) {
        logger.verbose(`Failed to read bake file ${bakeFile}: ${e}`);
      }
    }
    logger.verbose("Validating targets and TAG_VER variables...");
    const validationErrors = validateTargetsAndVariables(config, allBakeTargets, parsedBakeConfigs);
    const targetsDisplayData = [];
    if (!options.quiet) {
      const displayTargets = /* @__PURE__ */ new Set();
      const configTargets = Object.keys(config.targets || {});
      for (const targetName of configTargets) {
        displayTargets.add(targetName);
      }
      if (serviceFilterSet && serviceFilterSet.size > 0) {
        for (const targetName of serviceFilterSet) {
          displayTargets.add(targetName);
        }
      } else {
        for (const targetName of Object.keys(allBakeTargets)) {
          displayTargets.add(targetName);
        }
      }
      const sortedDisplayTargets = Array.from(displayTargets).sort();
      for (const targetName of sortedDisplayTargets) {
        const isInBake = targetName in allBakeTargets;
        const targetConfig = config.targets?.[targetName];
        targetsDisplayData.push({
          name: targetName,
          calculationCriteria: formatCalculationCriteria(targetConfig?.calculate_on),
          tagVer: "",
          // Filled later if calculation succeeds
          status: isInBake ? "success" : "not_found"
        });
      }
    }
    if (validationErrors.length > 0) {
      if (!options.quiet && targetsDisplayData.length > 0) {
        const hasErrors = targetsDisplayData.some((t) => t.status === "not_found");
        const headerEmoji = hasErrors ? "🔴" : "✅";
        console.log("");
        console.log(`${headerEmoji} Calculating targets:`);
        displayTargetsSection(targetsDisplayData);
        console.log("");
        console.log("❌ Errors:");
        for (const error of validationErrors) {
          console.log(`❌ ${error}`);
        }
      }
      return {
        success: false,
        outputFile,
        projectContext: contextDir,
        project: projectConfig,
        servicesCalculated: 0,
        generatedServices: [],
        resolvedTags: {},
        composeFiles,
        bakeTargets: allBakeTargets,
        errors: validationErrors
      };
    }
    logger.verbose("Building dependency tree...");
    const dependencyTree = buildDependencyTree(allBakeTargets);
    let servicesInOrder = getServicesInDependencyOrder(dependencyTree);
    logger.verbose(`Services in dependency order: ${servicesInOrder.join(", ")}`);
    let effectiveServiceFilter;
    if (serviceFilterSet && serviceFilterSet.size > 0) {
      effectiveServiceFilter = collectDependencyClosure(dependencyTree, serviceFilterSet);
      const imageAncestryTree = buildImageAncestryTree(allBakeTargets);
      const buildDependencies = collectDependencyClosure(imageAncestryTree, serviceFilterSet);
      for (const service of buildDependencies) {
        effectiveServiceFilter.add(service);
      }
      servicesInOrder = servicesInOrder.filter((service) => effectiveServiceFilter?.has(service) ?? false);
      logger.verbose(`Filtered services for calculation: ${servicesInOrder.join(", ")}`);
    }
    logger.verbose("Generating calculated HCL content...");
    const absoluteComposeFiles = composeFiles.map((file) => node_path.join(contextDir, file));
    const { hclOutput, generatedServices, resolvedTags } = await generateCalculatedHcl(
      config,
      allBakeTargets,
      servicesInOrder,
      contextDir,
      logger,
      buildHashInput,
      void 0,
      // Use default HCL config
      absoluteComposeFiles
      // Pass compose files for tag resolution
    );
    if (!options.quiet) {
      for (const service of generatedServices) {
        const targetData = targetsDisplayData.find((t) => t.name === service.name);
        if (targetData) {
          targetData.tagVer = service.imageTag;
          targetData.composeTag = service.composeTag;
          targetData.status = "success";
        }
      }
      const hasErrors = targetsDisplayData.some((t) => t.status === "not_found");
      const headerEmoji = hasErrors ? "🔴" : "✅";
      console.log("");
      console.log(`${headerEmoji} Calculating targets:`);
      displayTargetsSection(targetsDisplayData);
    }
    logger.verbose(`Writing output to: ${outputFile}`);
    const headerContent = `## ############################################################################
## This file is generated by orcka, and can be empty by default.
## orcka sets TAG values calculated according to criteria specified in
## docker-sha.yml and service ancestry (target.depends_on) in docker-bake.hcl
## ############################################################################

`;
    const finalOutput = headerContent + hclOutput;
    if (shouldWriteOutput) {
      node_fs.writeFileSync(outputFile, finalOutput, "utf-8");
    }
    if (!options.quiet) {
      const outputLabel = node_path.relative(projectDir, outputFile);
      const headerLabel = shouldWriteOutput ? "Wrote files" : "Would write files";
      console.log("");
      console.log(`✅ ${headerLabel}:`);
      console.log(`  • ${outputLabel}`);
      if (generatedServices.length > 0) {
        console.log("  • TAG_VER values:");
        const varNameWidth = Math.max(...generatedServices.map((service) => service.varName.length));
        for (const service of generatedServices) {
          const paddedVarName = service.varName.padEnd(varNameWidth);
          console.log(`    - ${paddedVarName} = "${service.imageTag}"`);
        }
      }
    }
    if (options.dotFile) {
      logger.verbose(`Generating DOT file: ${options.dotFile}`);
      const dotDependencyTree = buildImageAncestryTree(allBakeTargets);
      generateDotFile(config, dotDependencyTree, options.dotFile);
      logger.success(`Generated ${options.dotFile}`);
    }
    if (options.ascii) {
      logger.verbose("Generating ASCII tree visualization...");
      const treeGenerator = new AsciiTreeGenerator();
      const dependencyMap = buildDependencyMap(dependencyTree);
      const asciiTree = treeGenerator.generateTree(
        allBakeTargets,
        dependencyMap,
        options.inputFile,
        projectConfig.bake || []
      );
      console.log(asciiTree);
    }
    const resolvedTagRecord = Object.fromEntries(resolvedTags.entries());
    return {
      success: true,
      outputFile,
      projectContext: contextDir,
      project: projectConfig,
      servicesCalculated: generatedServices.length,
      generatedServices,
      resolvedTags: resolvedTagRecord,
      composeFiles,
      bakeTargets: allBakeTargets
    };
  } catch (error) {
    if (error instanceof CyclicDependencyError) {
      const errorMsg2 = `Cyclic dependencies detected: ${error.cycles.map((cycle) => cycle.join(" -> ")).join(", ")}`;
      logger.error(errorMsg2);
      const project2 = projectConfig ?? { name: "orcka", bake: [] };
      return {
        success: false,
        outputFile,
        projectContext: contextDir,
        project: project2,
        servicesCalculated: 0,
        generatedServices: [],
        resolvedTags: {},
        composeFiles,
        bakeTargets: allBakeTargets,
        errors: [errorMsg2]
      };
    }
    const errorMsg = error instanceof Error ? error.message : String(error);
    logger.error(errorMsg);
    const project = projectConfig ?? { name: "orcka", bake: [] };
    return {
      success: false,
      outputFile,
      projectContext: contextDir,
      project,
      servicesCalculated: 0,
      generatedServices: [],
      resolvedTags: {},
      composeFiles,
      bakeTargets: allBakeTargets,
      errors: [errorMsg]
    };
  }
}
function runDockerCommand(command) {
  try {
    node_child_process.execSync(command, { stdio: "pipe", encoding: "utf-8" });
    return true;
  } catch {
    return false;
  }
}
function getDockerCommandOutput(command) {
  try {
    return node_child_process.execSync(command, { stdio: "pipe", encoding: "utf-8" });
  } catch {
    return null;
  }
}
function checkDockerAvailable() {
  try {
    node_child_process.execSync("docker info", {
      stdio: "pipe",
      encoding: "utf-8",
      timeout: 3e3
    });
    return { available: true };
  } catch (error) {
    return {
      available: false,
      error: error instanceof Error ? error.message : "Docker daemon unavailable"
    };
  }
}
function checkImageAvailability(images) {
  return images.map((image) => {
    const psOutput = getDockerCommandOutput(`docker ps --filter ancestor=${image} --format '{{.ID}}'`);
    const running = psOutput !== null && psOutput.trim().length > 0;
    const local = runDockerCommand(`docker image inspect ${image}`);
    const remote = runDockerCommand(`docker manifest inspect ${image}`);
    return {
      image,
      running,
      local,
      remote
    };
  });
}
function generateComposeOverridesYaml(services, pullPolicy) {
  const sortedServices = [...services].sort();
  const doc = {
    services: Object.fromEntries(sortedServices.map((serviceName) => [serviceName, { pull_policy: pullPolicy }]))
  };
  return yaml.stringify(doc, { indent: 2 });
}
const COMPOSE_FILE_CANDIDATES = ["docker-compose.yml", "docker-compose.yaml", "compose.yml", "compose.yaml"];
function locateComposeFile(configFile, projectContext) {
  const searchDirs = /* @__PURE__ */ new Set([node_path.dirname(configFile)]);
  if (projectContext) {
    searchDirs.add(projectContext);
  }
  const checked = [];
  for (const dir of searchDirs) {
    for (const candidate of COMPOSE_FILE_CANDIDATES) {
      const candidatePath = node_path.resolve(dir, candidate);
      checked.push(candidatePath);
      if (node_fs.existsSync(candidatePath)) {
        return { composeFile: candidatePath, checked };
      }
    }
  }
  return { checked };
}
function parseWithPositionals(argv, config) {
  const optionArgs = [];
  const positionals = [];
  const argMap = /* @__PURE__ */ new Map();
  for (const [key, def] of Object.entries(config.args)) {
    for (const name of def.names) {
      argMap.set(name, { key, def });
    }
  }
  let i = 0;
  while (i < argv.length) {
    const token = argv[i];
    if (!token.startsWith("-")) {
      positionals.push(token);
      i++;
      continue;
    }
    optionArgs.push(token);
    const match = argMap.get(token);
    if (match?.def?.hasValue) {
      i++;
      if (i < argv.length) {
        optionArgs.push(argv[i]);
        if (match.def.multiValue) {
          while (i + 1 < argv.length && !argv[i + 1].startsWith("-")) {
            i++;
            optionArgs.push(argv[i]);
          }
        }
      }
    }
    i++;
  }
  const parsed = parseCommandArguments(optionArgs, config);
  return { parsed, positionals };
}
function writeComposeOverrideFile({
  statResult,
  services,
  pullPolicy,
  logger,
  quiet
}) {
  ensureOrckaDirectory(statResult.projectContext);
  const overridePath = resolveComposeOverridePath(statResult.projectContext, statResult.project);
  const overrideYaml = generateComposeOverridesYaml(services, pullPolicy);
  node_fs.writeFileSync(overridePath, overrideYaml, "utf-8");
  if (!quiet) {
    logger.info(`Generated compose override: ${overridePath}`);
  }
  return overridePath;
}
function resolveComposeFilesPaths({
  statResult,
  configPath,
  logger,
  quiet
}) {
  const baseDir = statResult.projectContext;
  const configured = statResult.composeFiles.map((file) => node_path.resolve(baseDir, file));
  const existing = configured.filter((file) => node_fs.existsSync(file));
  const missing = configured.filter((file) => !node_fs.existsSync(file));
  if (missing.length > 0 && !quiet) {
    for (const file of missing) {
      logger.warn(`Missing compose file referenced in configuration: ${file}`);
    }
  }
  if (existing.length > 0) {
    if (!quiet) {
      for (const file of existing) {
        logger.info(`Using compose file: ${file}`);
      }
    }
    return existing;
  }
  const { composeFile, checked } = locateComposeFile(configPath, statResult.projectContext);
  if (!composeFile) {
    console.error(`❌ Could not find a docker compose file. Checked: ${checked.join(", ")}`);
    process.exit(1);
  }
  logger.verbose(`Compose file search paths: ${checked.join(", ")}`);
  if (!quiet) {
    logger.info(`Using compose file: ${composeFile}`);
  }
  return [composeFile];
}
function reportImageAvailability(statResult, logger, quiet) {
  if (quiet) {
    return;
  }
  const images = Array.from(
    new Set(
      statResult.generatedServices.map((service) => service.imageReference || service.imageTag).filter((tag) => typeof tag === "string" && tag.length > 0)
    )
  );
  if (images.length === 0) {
    logger.info("No image tags produced during stat phase");
    return;
  }
  const dockerStatus = checkDockerAvailable();
  console.log(`
${Clout.statusLine("info", "Images: [C]ontainer [L]ocal [R]emote")}`);
  if (!dockerStatus.available) {
    console.log(Clout.statusLine("error", "Docker Services unavailable. Cannot fetch image info."));
    return;
  }
  const headers = ["Image", "C", "L", "R"];
  const maxImageLength = Math.max(...images.map((img) => img.length), 40);
  const availability = checkImageAvailability(images);
  const rows = availability.map((entry) => [
    entry.image,
    entry.running ? `[${Clout.symbols.star}]` : "[ ]",
    // C = Container (running)
    entry.local ? `[${Clout.symbols.checkmark}]` : "[ ]",
    // L = Local
    entry.remote ? `[${Clout.symbols.checkmark}]` : "[ ]"
    // R = Remote
  ]);
  const table2 = Clout.table(headers, rows, {
    columnWidths: [maxImageLength, 3, 3, 3],
    align: ["left", "center", "center", "center"],
    border: false,
    truncate: true
  });
  console.log(table2);
  console.log();
}
async function runStatCalculation({
  inputFile,
  dotFile,
  ascii,
  verbose,
  quiet,
  writeOutput = true,
  serviceFilter
}) {
  const result = await calculateDockerSha({
    inputFile,
    dotFile,
    ascii,
    verbose,
    quiet,
    writeOutput,
    serviceFilter
  });
  if (!result.success) {
    console.error("❌ Stat failed:");
    if (result.errors) {
      for (const error of result.errors) {
        console.error(`  - ${error}`);
      }
    }
    process.exit(1);
  }
  return result;
}
function resolveConfigFile(fileArg, quiet) {
  if (fileArg) {
    return { path: fileArg };
  }
  const discovery = new ConfigDiscovery();
  const discoveryResult = discovery.findConfigFile(".");
  if (!discoveryResult.found || !discoveryResult.filePath) {
    console.error(discovery.getNotFoundMessage("."));
    process.exit(1);
  }
  if (!quiet) {
    console.log(`🔍 Found configuration: ${discoveryResult.fileName}`);
  }
  return {
    path: discoveryResult.filePath,
    name: discoveryResult.fileName
  };
}
async function handleBuildCommand(argv) {
  try {
    const { parsed, positionals } = parseWithPositionals(argv, BuildCommandConfig);
    if (parsed.help) {
      handleCommandHelp(BUILD_HELP_TEXT);
      return;
    }
    const { verbose, quiet } = parseAndValidateCommonOptions(parsed);
    const skipValidation = Boolean(parsed["skip-validation"]);
    const logger = new Logger({ verbose, quiet });
    if (!skipValidation) {
      logger.verbose("🔍 Validating Docker environment...");
      const dockerValidation = await validateDockerEnvironment(logger);
      if (!dockerValidation.valid) {
        console.error("❌ Docker environment validation failed:");
        for (const error of dockerValidation.errors) {
          console.error(`  - ${error}`);
        }
        process.exit(1);
      }
      for (const warning of dockerValidation.warnings) {
        logger.warn(`⚠️  ${warning}`);
      }
      logger.verbose("✅ Docker environment validation passed");
    }
    const fileArg = typeof parsed.file === "string" ? parsed.file : void 0;
    const pullPolicy = typeof parsed["pull-policy"] === "string" ? parsed["pull-policy"] : "never";
    const resolved = resolveConfigFile(fileArg, quiet);
    if (!quiet) {
      logger.info(`Building with configuration: ${resolved.path}`);
    }
    const selectedServices = /* @__PURE__ */ new Set();
    const positionalTokens = [...positionals];
    const shouldRunUp = positionalTokens[0] === "up";
    if (shouldRunUp) {
      positionalTokens.shift();
    }
    for (const token of positionalTokens) {
      selectedServices.add(token);
    }
    if (typeof parsed.target === "string" && parsed.target.length > 0) {
      selectedServices.add(parsed.target);
    }
    const serviceFilter = selectedServices.size > 0 ? Array.from(selectedServices) : void 0;
    const statResult = await runStatCalculation({
      inputFile: resolved.path,
      verbose,
      quiet,
      writeOutput: true,
      serviceFilter
    });
    reportImageAvailability(statResult, logger, quiet);
    if (!quiet && statResult.generatedServices.length > 0) {
      const imageReferences = statResult.generatedServices.map((s) => s.imageReference);
      logger.verbose("🔍 Analyzing Docker registries...");
      const registryAnalysis = analyzeRegistries(imageReferences);
      displayRegistrySection(registryAnalysis);
    }
    const serviceNamesForOverride = Array.from(
      new Set(statResult.generatedServices.map((service) => service.name))
    ).sort();
    let overridePath;
    const shouldWriteOverride = statResult.project.buildtime?.apply_compose_tags === true || shouldRunUp;
    if (shouldWriteOverride) {
      overridePath = writeComposeOverrideFile({
        statResult,
        services: serviceNamesForOverride,
        pullPolicy,
        logger,
        quiet
      });
    }
    logger.verbose("🔍 Checking docker buildx bake availability...");
    const bakeAvailability = await DockerBakeExecutor.checkBakeAvailability();
    if (!bakeAvailability.available) {
      console.error(`❌ ${bakeAvailability.error}`);
      process.exit(1);
    }
    const buildTargets = (() => {
      if (selectedServices.size === 0) {
        return void 0;
      }
      const ancestryTree = buildImageAncestryTree(statResult.bakeTargets);
      return Array.from(collectDependencyClosure(ancestryTree, selectedServices)).sort();
    })();
    logger.info("🚀 Executing docker buildx bake...");
    const bakeResult = await executeBake(
      {
        configFile: resolved.path,
        targets: buildTargets,
        extraBakeFiles: typeof parsed["extra-bake"] === "string" ? [parsed["extra-bake"]] : void 0,
        extraComposeFiles: typeof parsed["extra-compose"] === "string" ? [parsed["extra-compose"]] : void 0,
        generatedServices: statResult.generatedServices,
        // Pass for dual tagging
        verbose,
        quiet
      },
      logger
    );
    if (!bakeResult.success) {
      console.error("❌ Docker build failed:");
      if (bakeResult.error) {
        console.error(`  ${bakeResult.error}`);
      }
      process.exit(bakeResult.exitCode ?? 1);
    }
    logger.success("✅ Build completed successfully!");
    if (shouldRunUp) {
      const ensuredOverridePath = overridePath ?? writeComposeOverrideFile({
        statResult,
        services: serviceNamesForOverride,
        pullPolicy,
        logger,
        quiet
      });
      const composeFiles = resolveComposeFilesPaths({
        statResult,
        configPath: resolved.path,
        logger,
        quiet
      });
      const servicesToStart = selectedServices.size > 0 ? Array.from(selectedServices) : void 0;
      await runComposeUp({
        composeFiles: [...composeFiles, ensuredOverridePath],
        quiet,
        services: servicesToStart,
        detached: statResult.project.runtime?.background === true
      });
      logger.success("✅ Docker compose up completed");
    }
  } catch (error) {
    console.error(`Error: ${error}`);
    process.exit(1);
  }
}
const DOWN_HELP_TEXT = `
Usage: orcka down [options] [services...]

Stop and remove containers, networks, and volumes created by 'orcka up'.

Options:
  --file <path>          Path to orcka configuration file (auto-detected if not provided).
  --volumes, -v          Remove named volumes declared in the compose file.
  --verbose              Output detailed information.
  --quiet, -q            Suppress all output except errors.
  --help                 Show this help message.

Examples:
  orcka down                    # Stop all services
  orcka down web api            # Stop specific services
  orcka down --volumes          # Stop services and remove volumes
`;
async function handleDownCommand(argv) {
  try {
    const { parsed, positionals } = parseWithPositionals(argv, UpCommandConfig);
    if (parsed.help) {
      handleCommandHelp(DOWN_HELP_TEXT);
      return;
    }
    const { verbose, quiet } = parseAndValidateCommonOptions(parsed);
    const fileArg = typeof parsed.file === "string" ? parsed.file : void 0;
    const removeVolumes = Boolean(parsed.volumes);
    const logger = new Logger({ verbose, quiet });
    const resolved = resolveConfigFile(fileArg, quiet);
    if (!quiet) {
      console.log(`Stopping services with configuration: ${resolved.path}`);
    }
    const selectedServices = new Set(positionals);
    const statResult = await runStatCalculation({
      inputFile: resolved.path,
      verbose,
      quiet,
      writeOutput: false
    });
    const composeFiles = resolveComposeFilesPaths({
      statResult,
      configPath: resolved.path,
      logger,
      quiet
    });
    const servicesToStop = selectedServices.size > 0 ? Array.from(selectedServices) : void 0;
    const composeArgs = composeFiles.flatMap((f) => ["-f", f]);
    const volumesArg = removeVolumes ? ["--volumes"] : [];
    const servicesArg = servicesToStop || [];
    const downCommand = ["docker", "compose", ...composeArgs, "down", ...volumesArg, ...servicesArg];
    if (verbose) {
      logger.verbose(`Running: ${downCommand.join(" ")}`);
    }
    try {
      node_child_process.execSync(downCommand.join(" "), {
        encoding: "utf-8",
        stdio: quiet ? "pipe" : "inherit"
      });
      logger.success("✅ Docker compose down completed");
    } catch (error) {
      console.error(`❌ Docker compose down failed: ${error}`);
      process.exit(1);
    }
  } catch (error) {
    console.error(`Error: ${error}`);
    process.exit(1);
  }
}
async function modifyDockerCompose(filePath, logger) {
  const result = {
    success: false,
    modifiedServices: [],
    errors: [],
    warnings: []
  };
  try {
    logger.verbose(`Reading docker-compose file: ${filePath}`);
    const fileContent = node_fs.readFileSync(filePath, "utf-8");
    const config = yaml.parse(fileContent);
    if (!config.services) {
      result.errors.push("No services section found in docker-compose file");
      return result;
    }
    let modified = false;
    for (const [serviceName, service] of Object.entries(config.services)) {
      logger.verbose(`Processing service: ${serviceName}`);
      const serviceModified = modifyService(serviceName, service, logger);
      if (serviceModified) {
        modified = true;
        result.modifiedServices.push(serviceName);
      }
    }
    if (modified) {
      const modifiedContent = yaml.stringify(config, {
        indent: 2,
        lineWidth: -1
        // Disable line wrapping
      });
      node_fs.writeFileSync(filePath, modifiedContent, "utf-8");
      logger.info(`✅ Modified ${filePath} - updated ${result.modifiedServices.length} services`);
      result.success = true;
    } else {
      logger.info(`ℹ️  No modifications needed for ${filePath}`);
      result.success = true;
    }
    return result;
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    logger.error(`Failed to modify docker-compose file: ${errorMsg}`);
    result.errors.push(errorMsg);
    return result;
  }
}
function modifyService(serviceName, service, logger) {
  let modified = false;
  if (service.image) {
    const imageModified = modifyImageField(serviceName, service, logger);
    if (imageModified) {
      modified = true;
    }
  }
  if (service.image) {
    const pullPolicyModified = addPullPolicyField(serviceName, service, logger);
    if (pullPolicyModified) {
      modified = true;
    }
  }
  return modified;
}
function modifyImageField(serviceName, service, logger) {
  if (!service.image) return false;
  const image = service.image;
  if (image.includes("${") || image.includes("$")) {
    logger.verbose(`Skipping ${serviceName}: image already uses variables`);
    return false;
  }
  const colonIndex = image.lastIndexOf(":");
  if (colonIndex === -1) {
    logger.verbose(`Skipping ${serviceName}: no tag specified in image`);
    return false;
  }
  const imageName = image.substring(0, colonIndex);
  const originalTag = image.substring(colonIndex + 1);
  if (/^\d+$/.test(originalTag)) {
    logger.verbose(`Skipping ${serviceName}: tag appears to be a port number`);
    return false;
  }
  const varName = serviceName.replace(/-/g, "_").toUpperCase();
  const tagVerVar = `${varName}_TAG_VER`;
  const newImage = `${imageName}:\${${tagVerVar}-${originalTag}}`;
  service.image = newImage;
  logger.verbose(`Modified ${serviceName}: ${image} → ${newImage}`);
  return true;
}
function addPullPolicyField(serviceName, service, logger) {
  const varName = serviceName.replace(/-/g, "_").toUpperCase();
  const pullPolicyVar = `${varName}_PULL_POLICY`;
  const newPullPolicy = `\${${pullPolicyVar}-missing}`;
  if (service.pull_policy && (service.pull_policy.includes("${") || service.pull_policy.includes("$"))) {
    logger.verbose(`Skipping ${serviceName}: pull_policy already uses variables`);
    return false;
  }
  const oldPullPolicy = service.pull_policy;
  service.pull_policy = newPullPolicy;
  if (oldPullPolicy) {
    logger.verbose(`Modified ${serviceName}: pull_policy ${oldPullPolicy} → ${newPullPolicy}`);
  } else {
    logger.verbose(`Added ${serviceName}: pull_policy = ${newPullPolicy}`);
  }
  return true;
}
async function handleModifyCommand(argv) {
  try {
    const parsed = parseCommandArguments(argv, ModifyCommandConfig);
    if (parsed.help) {
      handleCommandHelp(MODIFY_HELP_TEXT);
      return;
    }
    if (!parsed.file || typeof parsed.file !== "string") {
      console.error("Error: --file is required for modify command and must be a string");
      process.exit(1);
    }
    const { verbose } = parseAndValidateCommonOptions(parsed);
    const logger = new Logger({ verbose, quiet: false });
    console.log(`Modifying docker-compose file: ${parsed.file}`);
    const modifyResult = await modifyDockerCompose(parsed.file, logger);
    if (!modifyResult.success) {
      console.error("❌ Modify failed:");
      for (const error of modifyResult.errors) {
        console.error(`  - ${error}`);
      }
      process.exit(1);
    }
    if (modifyResult.modifiedServices.length > 0) {
      console.log(`✅ Successfully modified ${modifyResult.modifiedServices.length} services:`);
      for (const service of modifyResult.modifiedServices) {
        console.log(`  - ${service}`);
      }
    } else {
      console.log("ℹ️  No modifications were needed");
    }
  } catch (error) {
    console.error(`Error: ${error}`);
    process.exit(1);
  }
}
async function handleRunCommand(argv) {
  try {
    const { parsed, positionals } = parseWithPositionals(argv, RunCommandConfig);
    if (parsed.help) {
      handleCommandHelp(RUN_HELP_TEXT);
      return;
    }
    const { verbose, quiet } = parseAndValidateCommonOptions(parsed);
    const fileArg = typeof parsed.file === "string" ? parsed.file : void 0;
    const pullPolicy = typeof parsed["pull-policy"] === "string" ? parsed["pull-policy"] : "never";
    const skipBuild = parsed["skip-build"] === true;
    const detached = parsed.detached === true;
    const logger = new Logger({ verbose, quiet });
    const resolved = resolveConfigFile(fileArg, quiet);
    if (!quiet) {
      logger.info(`🚀 Running services with configuration: ${resolved.path}`);
    }
    const selectedServices = new Set(positionals);
    if (typeof parsed.target === "string" && parsed.target.length > 0) {
      selectedServices.add(parsed.target);
    }
    const serviceFilter = selectedServices.size > 0 ? Array.from(selectedServices) : void 0;
    logger.verbose("📊 Calculating image tags...");
    const statResult = await runStatCalculation({
      inputFile: resolved.path,
      verbose,
      quiet,
      writeOutput: true,
      serviceFilter
    });
    if (!statResult.success) {
      console.error("❌ Failed to calculate image tags");
      process.exit(1);
    }
    logger.verbose("🔍 Checking image availability...");
    const imageReferences = statResult.generatedServices.map((s) => s.imageReference);
    const imageAvailability = checkImageAvailability(imageReferences);
    const missingImages = imageAvailability.filter((img) => !img.local);
    if (!quiet) {
      displayRunPlan(statResult, imageAvailability, selectedServices);
      const imageReferences2 = statResult.generatedServices.map((s) => s.imageReference);
      logger.verbose("🔍 Analyzing Docker registries...");
      const registryAnalysis = analyzeRegistries(imageReferences2);
      displayRegistrySection(registryAnalysis);
    }
    if (missingImages.length > 0 && !skipBuild) {
      logger.info(`🔨 Building ${missingImages.length} missing image(s)...`);
      const bakeAvailability = await DockerBakeExecutor.checkBakeAvailability();
      if (!bakeAvailability.available) {
        console.error(`❌ ${bakeAvailability.error}`);
        process.exit(1);
      }
      const missingServiceNames = missingImages.map((img) => {
        const service = statResult.generatedServices.find((s) => s.imageReference === img.image);
        return service?.name;
      }).filter((name) => name !== void 0);
      const buildTargets = Array.from(
        collectDependencyClosure(
          buildImageAncestryTree(statResult.bakeTargets),
          new Set(missingServiceNames)
        )
      ).sort();
      logger.verbose(`🎯 Building targets: ${buildTargets.join(", ")}`);
      const bakeResult = await executeBake(
        {
          configFile: resolved.path,
          targets: buildTargets,
          generatedServices: statResult.generatedServices,
          verbose,
          quiet
        },
        logger
      );
      if (!bakeResult.success) {
        console.error("❌ Build failed:");
        if (bakeResult.error) {
          console.error(`  ${bakeResult.error}`);
        }
        process.exit(bakeResult.exitCode ?? 1);
      }
      logger.success("✅ Images built successfully");
    } else if (missingImages.length > 0 && skipBuild) {
      logger.warn(`⚠️  ${missingImages.length} image(s) missing but build skipped (--skip-build)`);
    } else if (!quiet) {
      logger.success("✅ All images are available locally");
    }
    const serviceNamesForOverride = Array.from(
      new Set(statResult.generatedServices.map((service) => service.name))
    ).sort();
    const overridePath = writeComposeOverrideFile({
      statResult,
      services: serviceNamesForOverride,
      pullPolicy,
      logger,
      quiet
    });
    const composeFiles = resolveComposeFilesPaths({
      statResult,
      configPath: resolved.path,
      logger,
      quiet
    });
    const allComposeFiles = overridePath ? [...composeFiles, overridePath] : composeFiles;
    const servicesToRun = serviceFilter || void 0;
    logger.info(`🚀 Starting services${detached ? " (detached)" : ""}...`);
    runComposeUp({
      composeFiles: allComposeFiles,
      quiet,
      services: servicesToRun,
      detached
    });
    if (!quiet) {
      logger.success(`✅ Services ${detached ? "started" : "running"}`);
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    console.error(`❌ Run failed: ${errorMsg}`);
    process.exit(1);
  }
}
function displayRunPlan(statResult, imageAvailability, selectedServices) {
  console.log("");
  console.log("📋 Run Plan:");
  console.log("");
  const servicesToRun = selectedServices.size > 0 ? statResult.generatedServices.filter((s) => selectedServices.has(s.name)) : statResult.generatedServices;
  console.log(`  Services to start: ${servicesToRun.length}`);
  for (const service of servicesToRun) {
    const availability = imageAvailability.find((img) => img.image === service.imageReference);
    const status = getServiceStatus(availability);
    console.log(`    • ${service.name}: ${status}`);
  }
  const runningServices = servicesToRun.filter((service) => {
    const availability = imageAvailability.find((img) => img.image === service.imageReference);
    return availability?.running;
  });
  if (runningServices.length > 0) {
    console.log("");
    console.log(`  ⚠️  ${runningServices.length} service(s) already running:`);
    for (const service of runningServices) {
      console.log(`    • ${service.name}`);
    }
  }
  const missingServices = servicesToRun.filter((service) => {
    const availability = imageAvailability.find((img) => img.image === service.imageReference);
    return !availability?.local;
  });
  if (missingServices.length > 0) {
    console.log("");
    console.log(`  🔨 ${missingServices.length} image(s) will be built:`);
    for (const service of missingServices) {
      console.log(`    • ${service.name} → ${service.imageReference}`);
    }
  }
  console.log("");
}
function getServiceStatus(availability) {
  if (!availability) {
    return "❓ unknown";
  }
  if (availability.running) {
    return "🟢 running";
  }
  if (availability.local) {
    return "✅ ready";
  }
  if (availability.remote) {
    return "📦 remote (will build)";
  }
  return "❌ missing (will build)";
}
async function handleStatCommand(argv, options = {}) {
  try {
    const parsed = parseCommandArguments(argv, StatCommandConfig);
    if (parsed.help) {
      handleCommandHelp(STAT_HELP_TEXT);
      return;
    }
    const { verbose, quiet } = parseAndValidateCommonOptions(parsed);
    const dotFile = typeof parsed.dotfile === "string" ? parsed.dotfile : void 0;
    const ascii = Boolean(parsed.ascii);
    const fileArg = typeof parsed.file === "string" ? parsed.file : void 0;
    const logger = new Logger({ verbose, quiet });
    if (!quiet && options.invokedByDefault) {
      logger.info("Running default stat command. Use `orcka stat --help` for options.");
    }
    const resolved = resolveConfigFile(fileArg, quiet);
    if (!quiet) {
      logger.info(`Calculating docker-sha configuration from: ${resolved.path}`);
    }
    const statResult = await runStatCalculation({
      inputFile: resolved.path,
      dotFile,
      ascii,
      verbose,
      quiet,
      writeOutput: false
    });
    reportImageAvailability(statResult, logger, quiet);
    if (!quiet && statResult.generatedServices.length > 0) {
      const imageReferences = statResult.generatedServices.map((s) => s.imageReference);
      logger.verbose("🔍 Analyzing Docker registries...");
      const registryAnalysis = analyzeRegistries(imageReferences);
      displayRegistrySection(registryAnalysis);
    }
  } catch (error) {
    console.error(`Error: ${error}`);
    process.exit(1);
  }
}
async function handleUpCommand(argv) {
  try {
    const { parsed, positionals } = parseWithPositionals(argv, UpCommandConfig);
    if (parsed.help) {
      handleCommandHelp(UP_HELP_TEXT);
      return;
    }
    const { verbose, quiet } = parseAndValidateCommonOptions(parsed);
    const fileArg = typeof parsed.file === "string" ? parsed.file : void 0;
    const pullPolicy = typeof parsed["pull-policy"] === "string" ? parsed["pull-policy"] : "never";
    const logger = new Logger({ verbose, quiet });
    const resolved = resolveConfigFile(fileArg, quiet);
    if (!quiet) {
      logger.info(`Starting services with configuration: ${resolved.path}`);
    }
    const selectedServices = new Set(positionals);
    if (typeof parsed.target === "string" && parsed.target.length > 0) {
      selectedServices.add(parsed.target);
    }
    const serviceFilter = selectedServices.size > 0 ? Array.from(selectedServices) : void 0;
    const statResult = await runStatCalculation({
      inputFile: resolved.path,
      verbose,
      quiet,
      writeOutput: true,
      serviceFilter
    });
    reportImageAvailability(statResult, logger, quiet);
    const serviceNamesForOverride = Array.from(
      new Set(statResult.generatedServices.map((service) => service.name))
    ).sort();
    const overridePath = writeComposeOverrideFile({
      statResult,
      services: serviceNamesForOverride,
      pullPolicy,
      logger,
      quiet
    });
    const composeFiles = resolveComposeFilesPaths({
      statResult,
      configPath: resolved.path,
      logger,
      quiet
    });
    const servicesToStart = selectedServices.size > 0 ? Array.from(selectedServices) : void 0;
    await runComposeUp({
      composeFiles: [...composeFiles, overridePath],
      quiet,
      services: servicesToStart,
      detached: statResult.project.runtime?.background === true
    });
    logger.success("✅ Docker compose up completed");
  } catch (error) {
    console.error(`Error: ${error}`);
    process.exit(1);
  }
}
function resolveDockerConfigPath() {
  const customConfig = process.env.DOCKER_CONFIG;
  if (customConfig && customConfig.length > 0) {
    return customConfig;
  }
  const homeDir = process.env.HOME ?? process.env.USERPROFILE ?? ".";
  return node_path.join(homeDir, ".docker", "config.json");
}
function loadAuthMap() {
  try {
    const configPath = resolveDockerConfigPath();
    if (!node_fs.existsSync(configPath)) {
      return {};
    }
    const contents = node_fs.readFileSync(configPath, "utf-8");
    const parsed = JSON.parse(contents);
    return parsed.auths ?? {};
  } catch {
    return {};
  }
}
function registryHasAuth(registryName, auths) {
  const candidates = [
    registryName,
    `https://${registryName}`,
    `https://${registryName}/v1/`,
    `https://${registryName}/v2/`
  ];
  return candidates.some((candidate) => candidate in auths);
}
function gatherRegistryInfo() {
  try {
    const raw = node_child_process.execSync("docker info --format {{json .RegistryConfig.IndexConfigs}}", { encoding: "utf-8" });
    const parsed = raw ? JSON.parse(raw) : {};
    const auths = loadAuthMap();
    return Object.keys(parsed).sort().map((name) => ({
      name,
      authenticated: registryHasAuth(name, auths)
    }));
  } catch {
    return [];
  }
}
async function handleWorkflowCommand(argv) {
  try {
    const { parsed, positionals } = parseWithPositionals(argv, WorkflowCommandConfig);
    if (parsed.help) {
      handleCommandHelp(WORKFLOW_HELP_TEXT);
      return;
    }
    const { verbose, quiet } = parseAndValidateCommonOptions(parsed);
    const logger = new Logger({ verbose, quiet });
    const fileArg = typeof parsed.file === "string" ? parsed.file : void 0;
    const pullPolicy = typeof parsed["pull-policy"] === "string" ? parsed["pull-policy"] : "never";
    const skipBake = Boolean(parsed["skip-bake"]);
    const skipUp = Boolean(parsed["skip-up"]);
    const showAncestry = Boolean(parsed.ancestry);
    const selectedServices = /* @__PURE__ */ new Set();
    for (const token of positionals) {
      selectedServices.add(token);
    }
    const resolved = resolveConfigFile(fileArg, quiet);
    if (!quiet) {
      logger.info(`Running workflow with configuration: ${resolved.path}`);
    }
    const statResult = await runStatCalculation({
      inputFile: resolved.path,
      ascii: showAncestry,
      verbose,
      quiet,
      writeOutput: true,
      serviceFilter: selectedServices.size > 0 ? Array.from(selectedServices) : void 0
    });
    const registrySummaries = gatherRegistryInfo();
    if (!quiet) {
      if (registrySummaries.length === 0) {
        logger.info("Registry authentication status: (none reported)");
      } else {
        logger.info("Registry authentication status:");
        for (const summary of registrySummaries) {
          const statusEmoji = summary.authenticated ? "✅" : "⚠️";
          logger.info(`  ${statusEmoji} ${summary.name}`);
        }
      }
    }
    reportImageAvailability(statResult, logger, quiet);
    if (!skipBake) {
      logger.info("Checking docker buildx bake availability...");
      const bakeAvailability = await DockerBakeExecutor.checkBakeAvailability();
      if (!bakeAvailability.available) {
        console.error(`❌ ${bakeAvailability.error}`);
        process.exit(1);
      }
      const buildTargets = selectedServices.size === 0 ? void 0 : Array.from(
        collectDependencyClosure(buildImageAncestryTree(statResult.bakeTargets), selectedServices)
      ).sort();
      logger.info("Executing docker buildx bake...");
      const bakeResult = await executeBake(
        {
          configFile: resolved.path,
          targets: buildTargets,
          generatedServices: statResult.generatedServices,
          // Pass for dual tagging
          verbose,
          quiet
        },
        logger
      );
      if (!bakeResult.success) {
        console.error("❌ Docker build failed:");
        if (bakeResult.error) {
          console.error(`  ${bakeResult.error}`);
        }
        process.exit(bakeResult.exitCode ?? 1);
      }
      logger.success("✅ Docker bake completed successfully");
    } else if (!quiet) {
      logger.info("Skipping bake stage (--skip-bake)");
    }
    if (!skipUp) {
      const serviceNamesForOverride = Array.from(
        new Set(statResult.generatedServices.map((service) => service.name))
      ).sort();
      const overridePath = writeComposeOverrideFile({
        statResult,
        services: serviceNamesForOverride,
        pullPolicy,
        logger,
        quiet
      });
      const composeFiles = resolveComposeFilesPaths({
        statResult,
        configPath: resolved.path,
        logger,
        quiet
      });
      const servicesToStart = selectedServices.size > 0 ? Array.from(selectedServices) : void 0;
      await runComposeUp({
        composeFiles: [...composeFiles, overridePath],
        quiet,
        services: servicesToStart,
        detached: statResult.project.runtime?.background === true
      });
      logger.success("✅ Docker compose up completed");
    } else if (!quiet) {
      logger.info("Skipping compose up stage (--skip-up)");
    }
  } catch (error) {
    console.error(`Error: ${error}`);
    process.exit(1);
  }
}
async function handleWriteCommand(argv) {
  try {
    const parsed = parseCommandArguments(argv, WriteCommandConfig);
    if (parsed.help) {
      handleCommandHelp(WRITE_HELP_TEXT);
      return;
    }
    const { verbose, quiet } = parseAndValidateCommonOptions(parsed);
    const fileArg = typeof parsed.file === "string" ? parsed.file : void 0;
    const pullPolicy = typeof parsed["pull-policy"] === "string" ? parsed["pull-policy"] : "never";
    const resolved = resolveConfigFile(fileArg, quiet);
    if (!quiet) {
      console.log(`Generating compose overrides from: ${resolved.path}`);
    }
    const statResult = await runStatCalculation({
      inputFile: resolved.path,
      verbose,
      quiet,
      writeOutput: true
    });
    const serviceNames = statResult.generatedServices.map((service) => service.name);
    const overrideYaml = generateComposeOverridesYaml(serviceNames, pullPolicy);
    ensureOrckaDirectory(statResult.projectContext);
    const defaultOutputPath = resolveComposeOverridePath(statResult.projectContext, statResult.project);
    const outputPath = typeof parsed.output === "string" ? parsed.output : defaultOutputPath;
    node_fs.writeFileSync(outputPath, overrideYaml, "utf-8");
    if (!quiet) {
      console.log(`✅ Wrote compose override file: ${outputPath}`);
    }
  } catch (error) {
    console.error(`Error: ${error}`);
    process.exit(1);
  }
}
const BUILD_INFO = {
  buildDate: "2025-10-02T13:28:58.073Z",
  gitSha: "18ddc5612b4a8ea8e1c768cb6504786c107591b3",
  gitBranch: "HEAD",
  repoUrl: "https://github.com/camsnz/orcka"
};
const orckaBanner = () => Clout.banner("Orca: orchestrate docker/compose/bake with advanced shasum-tag integration", {
  dividerChar: "-",
  align: "center",
  padding: { top: 0, bottom: 0, left: 1, right: 1 }
});
function showVersion() {
  console.log(orckaBanner());
  console.log();
  console.log(Clout.keyValue("Version", BUILD_INFO.gitSha, { keyWidth: 10 }));
  console.log(Clout.keyValue("Built", BUILD_INFO.buildDate, { keyWidth: 10 }));
  console.log(Clout.keyValue("Branch", BUILD_INFO.gitBranch, { keyWidth: 10 }));
  console.log(Clout.keyValue("Source", BUILD_INFO.repoUrl, { keyWidth: 10 }));
}
function showMainUsage() {
  console.log(orckaBanner());
  console.log(`
Usage: orcka [command] [options]

Commands:
  stat               Validate configuration, compute tags, and emit HCL
  write              Generate docker-sha.hcl and compose overrides
  modify             Modify docker-compose.yml with calculated tags
  build              Build docker images using calculated tags
  up                 Start services using docker compose
  down               Stop and remove services, networks, and volumes
  run                Assess, auto-build missing images, and start services
  workflow           Run stat, checks, bake, and compose up as a single pipeline

Global Options:
  --help, -h   Show this help message
  --version, -v Show version information

Examples:
  orcka stat                     # Run validation and tag generation
  orcka stat --file orcka.yml    # Stat a specific config file
  orcka write                    # Write docker-sha.hcl and compose overrides
  orcka build --target web       # Build specific target with calculated tags
  orcka up                       # Start all services
  orcka down --volumes           # Stop services and remove volumes
  orcka run                      # Smart run: assess, build if needed, start
  orcka workflow                 # Execute the cached-build workflow

For command-specific help, use: orcka [command] --help
`);
}
const COMMAND_REGISTRY = {
  stat: (args) => handleStatCommand(args),
  write: handleWriteCommand,
  modify: handleModifyCommand,
  build: handleBuildCommand,
  up: handleUpCommand,
  down: handleDownCommand,
  run: handleRunCommand,
  workflow: handleWorkflowCommand
};
const GLOBAL_FLAGS = {
  "--help": () => {
    showMainUsage();
    process.exit(0);
  },
  "-h": () => {
    showMainUsage();
    process.exit(0);
  },
  "--version": () => {
    showVersion();
    process.exit(0);
  },
  "-v": () => {
    showVersion();
    process.exit(0);
  }
};
async function main() {
  const args = process.argv.slice(2);
  if (args.length === 0) {
    showMainUsage();
    process.exit(0);
  }
  const command = args[0];
  if (command in GLOBAL_FLAGS) {
    GLOBAL_FLAGS[command]();
    return;
  }
  if (command in COMMAND_REGISTRY) {
    await COMMAND_REGISTRY[command](args.slice(1));
    return;
  }
  console.error(`Unknown command: ${command}`);
  showMainUsage();
  process.exit(1);
}
if (require.main === module) {
  main();
}
exports.main = main;
